---
title: "MI_Flat_File_Aggregation"
author: "Mike Verhoeven"
date: "2Oct2024"
output: html_document
---
# Preamble

a few notes:
- Ages were excluded from this file
- We limited species in this because the files had different species extents
- In my dates exploration, I found a survey start and end dates, all surveys expect for 4 happen over a 7 day time frame
    -there is one gill netting case spanning May to Oct.
    -given the end date does not seem relevant to retain, I only keep survey start dates



##Libraries
```{r}
library(arrow)
library(readr)
library(dplyr)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)
library(bit64)
library(mwlaxeref)

options(scipen = 999)
```


##Data
```{r}
#generate a file list to import
files_list <- list.files(path = "G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MI_Data/mi_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

#object for use in loop (simple length of file list)
n <- length(files_list)

for(i in 1:n) {
  #i = 3
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("G:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MI_Data/mi_raw_disaggregated_data/",
                                          files_list[i])))
  
  # if the file is a crosswalk, do not rename anything, just loop to the confirm import line
  if(str_detect(filei, "crosswalk")) {  #confirm import of files:  
    print(paste(filei ,"added to workspace" ))  
    #confirm import of files:  
    print(paste(i ,"files added to workspace" )) ; next}
  
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    data.table::transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  
  # break the loop if the current file has column names not in the data explainer
  # if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  if (all(colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]) == FALSE ) break
  
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  #confirm import of files:  
  print(paste(i ,"files added to workspace" )) 

  
} 
  #confirm import of files:  
  print(paste(i ,"files added to workspace" ))
  #confirm import of files:  
  print(paste(n-i ,"remaining to be added" )) 



```


#Data Ag Prep
this chunk explores the structure of the data and does some foundation data ag
```{r}
#effort:
mi_statustrends_effort_16Mar2021[ , .N , .(lake_id, lake_name.1, date.1 , survey_type.1, sampling_method_abbrev)  ]

#some lake IDs seem to have >1 name:
mi_statustrends_effort_16Mar2021[  ,length(unique(lake_id)), .(lake_name.1)][V1>1] # lake names not unique (they usually aren't)
mi_statustrends_effort_16Mar2021[  ,length(unique(lake_name.1)), .(lake_id)][V1>1] # lake ids not unique (they *should* be though)

#which lakes have multiple names for a single ID?
mi_statustrends_effort_16Mar2021[  ,length(unique(lake_name.1)), .(lake_id)][V1>1][,lake_id]
mi_statustrends_effort_16Mar2021[lake_id %in% 
                                   mi_statustrends_effort_16Mar2021[  ,length(unique(lake_name.1)), .(lake_id)][V1>1][,lake_id], , ]
# it appears here that a full survey (all gears were deployed in each part of these lakes. For that reason, My vote is that we keep them separate and use lake_id + lake_name for our key. 

# view each data level for a single survey
mi_statustrends_effort_16Mar2021[survey_id ==2446]
mi_statustrends_catch_16Mar2021[survey_id == 2446]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, ]
mi_statustrends_lenage_20May2021[survey_id == 2446, ]

# do the counts match across all levels?
mi_statustrends_catch_16Mar2021[survey_id == 2446, sum(total_count.1)]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, sum(total_count.1)]
nrow(mi_statustrends_lenage_20May2021[survey_id == 2446, ])

#no. not even close. I suspect this is bc of a species selection that happened in the catch data:
mi_statustrends_catch_16Mar2021[survey_id == 2446, length(unique(species.1))]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, length(unique(species.1))]
mi_statustrends_lenage_20May2021[survey_id == 2446, length(unique(species.1)) ]
#view species lists:
mi_statustrends_catch_16Mar2021[survey_id == 2446,sum(total_count.1) , species.1]
mi_statustrends_catchlengthclass_03July2023[survey_id == 2446, sum(total_count.1) , species.1]
mi_statustrends_lenage_20May2021[survey_id == 2446, .N , species.1 ] # these numbers will not be the same. This is because these aged fish are a subset.
#view species lists:
mi_statustrends_catch_16Mar2021[survey_id == 4079,sum(total_count.1) , species.1]
mi_statustrends_catchlengthclass_03July2023[survey_id == 4079,sum(total_count.1) , species.1]
mi_statustrends_lenage_20May2021[survey_id == 4079, .N , species.1 ] # these numbers will not be the same. This is because these aged fish are a subset.



# not exactly clear WHY the numbers still don't jive between the inch grp file and the catch file, BUT the catch file seems to have problems with the n per species X gear where there are zeros in an inchgroup (see survey 2446)
# 
# There's currently a length = 1 and total.count = 0 that shows up in the inchclass file and those zeros seems to be counted in the catch summary file







#survey_ids matched across all surveys?
mi_statustrends_effort_16Mar2021[ , .( effort_nrows = .N) , survey_id]
mi_statustrends_catch_16Mar2021[ , .( catch_nrows = .N) , survey_id]
mi_statustrends_catchlengthclass_03July2023[ , .( catchlen_nrows = .N) , survey_id ]
mi_statustrends_lenage_20May2021[ , .( lenage_nrows = .N) , survey_id] 


  
data_coverage <- 
merge(
  merge(
  merge(
    merge(mi_statustrends_effort_16Mar2021[ , .( effort_nrows = .N) , survey_id], 
          mi_statustrends_catch_16Mar2021[ , .( catch_nrows = .N) , survey_id], all = T),
    mi_statustrends_catchlengthclass_03July2023[ , .( catchlen_nrows = .N) , survey_id ], all = T), 
  mi_statustrends_lenage_20May2021[ , .( lenage_nrows = .N) , survey_id], all = T),
  snt_lakes_info_unique_id[,.(crosswalk_nrows = .N) , Survey_Number ],by.x = "survey_id", by.y = "Survey_Number", all = T
)

#retaining more dates?
survey_dates <- mi_statustrends_catch_16Mar2021 %>% 
  select(survey_id, date.1, sample_time_notes.1) %>% 
  mutate(start = ymd(mdy(date.1)),
         end = str_replace(sample_time_notes.1, "SAMPLE_END_DATE:", ""),
         end = as.Date(end, format = "%m/%d/%Y"),
         duration = end - start) %>% 
  distinct(survey_id, .keep_all = T)
survey_dates %>% 
  summarise(min.dur = min(duration, na.rm = T), 
            max.dur = max(duration, na.rm = T),
            over.week = sum(duration > 7, na.rm = T))
#only 4 surveys that lasted longer than a week - two longest are survey id 4854 and 9316
mi_statustrends_catch_16Mar2021 %>% 
  filter(survey_id %in% c("4854", "9316")) %>% 
  group_by(survey_id, sampling_method_abbrev, date.1, sample_time_notes.1) %>% 
  count()
```


# Effort Merge
the bulk of the ag happens in this chunk
```{r}
#Start with a merge of catch and catch-length?

#file prep
#dates
# mi_statustrends_effort_16Mar2021[ , unique(date.1) , ]
mi_statustrends_effort_16Mar2021[ , date.1 := as.character(date.1) , ]
# mi_statustrends_catch_16Mar2021[ , unique(date.1) , ]
mi_statustrends_catch_16Mar2021[ , date.1 := as.character(as.IDate(date.1, format = "%m/%d/%Y")) , ]
#species        
#species is empty in effort
mi_statustrends_effort_16Mar2021[ , .N , species.1 ]
mi_statustrends_effort_16Mar2021[ , species.1 := NULL ,]

#view species lists:
mi_statustrends_catch_16Mar2021[ ,sum(total_count.1) , species.1]
mi_statustrends_catchlengthclass_03July2023[ ,sum(total_count.1) , species.1]
mi_statustrends_lenage_20May2021[ , .N , species.1 ] # these numbers will not be the same. This is because these aged fish are a subset.

#dump the species not of interest to us here:
mi_statustrends_catchlengthclass_03July2023 <- mi_statustrends_catchlengthclass_03July2023[species.1 %in% mi_statustrends_catch_16Mar2021[ , unique(species.1)]]

#column name diffs
colnames(mi_statustrends_catchlengthclass_03July2023)[colnames(mi_statustrends_catchlengthclass_03July2023)== "sampling_method.1" ] <- "sampling_method_abbrev"

#add lake_id to lengthclass file:
mi_statustrends_catchlengthclass_03July2023[mi_statustrends_effort_16Mar2021[ ,.N , .(lake_id, lake_name.1, survey_id)], on = c("lake_name.1", "survey_id"), lake_id := lake_id ] 
mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)]#still missing names

#any more available in catch file? NOPE
mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)][,survey_id]%in%
  mi_statustrends_catch_16Mar2021[ ,.N , .(lake_id, lake_name.1, survey_id)][ , survey_id]

#if drawn from effort sans survey ID (Risky, ambiguous join) can we get a 1:1 for lake name? or is there multi lakes for each name?
mi_statustrends_effort_16Mar2021[ lake_name.1 %in%
                                    mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)][,lake_name.1] , .N ,
                                  .(lake_id, county, lake_name.1, year, survey_id, survey_type.1) ]
#if drawn from catch sans survey ID (Risky, ambiguous join) can we get a 1:1 for lake name? or is there multi lakes for each name?
mi_statustrends_catch_16Mar2021[ lake_name.1 %in%
                                   mi_statustrends_catchlengthclass_03July2023[is.na(lake_id), .N , .(lake_name.1, survey_id)][,lake_name.1] , .N ,
                                 .(lake_id, county, lake_name.1, year, survey_id, survey_type.1) ]

#Conclusion-- don't do that. only grab the full keyed lake IDs from effort:
mi_statustrends_catchlengthclass_03July2023[mi_statustrends_catch_16Mar2021[ ,.N , .(lake_id, lake_name.1, survey_id)], on = c("lake_name.1", "survey_id"), lake_id := lake_id ]
#uncount catch
#uncount the catch files into an indiv-as-row format:
#with lengths scope
mi_statustrends_catchlengthclass_03July2023[ ,summary(total_count.1) , ]
mi_statustrends_catchlengthclass_03July2023[ , .N , total_count.1 == 0] #do we lose anything if we drop these?

#here we check if the surveyXsample methods are all covere in the >0 total_count.1 data (same dataset)
mi_statustrends_catchlengthclass_03July2023[total_count.1 == 0 , .N , .(survey_id, sampling_method_abbrev)]
sum(!mi_statustrends_catchlengthclass_03July2023[total_count.1 == 0 , paste(survey_id, sampling_method_abbrev)] %in% mi_statustrends_catchlengthclass_03July2023[total_count.1>0, paste(survey_id,sampling_method_abbrev)])
#how about in the effort data? There's no effort data that we would lose if we drop those zeros. 
sum(!mi_statustrends_catchlengthclass_03July2023[total_count.1 == 0 , paste(survey_id, sampling_method_abbrev)] %in% mi_statustrends_effort_16Mar2021[, paste(survey_id,sampling_method_abbrev)])

#execute the uncount, dropping those zero total counts in the mix (This line is generating a warning in the next line)
mi_statustrends_catchlengthclass_03July2023_uncount <- 
  uncount(mi_statustrends_catchlengthclass_03July2023[total_count.1!=0], total_count.1, .remove = T, .id = "ident_l")

#add a surveyxgear ident for indiv fish
mi_statustrends_catchlengthclass_03July2023_uncount[ , ident := seq_len(.N) , .(lake_name.1, lake_id, survey_id, sampling_method_abbrev, species.1) ]

#no lengths scope          
mi_statustrends_catch_16Mar2021[ , summary(total_count.1)]
#execute
mi_statustrends_catch_16Mar2021_uncount <- 
  uncount(mi_statustrends_catch_16Mar2021, total_count.1, .remove = T, .id = "ident")



#how many length data cover unknown surveys in catch data?

#here we check if the surveyXsample methods are all covered in the simple catch data
mi_statustrends_catchlengthclass_03July2023_uncount[ , .N , .(survey_id, sampling_method_abbrev)]
sum(!mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))] %in% mi_statustrends_catch_16Mar2021_uncount[, unique(paste(survey_id,sampling_method_abbrev))])

#how about in the effort data? There's no effort data that we would lose if we drop those zeros, but we do have 3 surveyXgears unique to the inchclass data. 
sum(!mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))] %in% mi_statustrends_effort_16Mar2021[, paste(survey_id,sampling_method_abbrev)])

# we can see that 3 surveys in inchclass data are not represented in catch or effort data
mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))][!mi_statustrends_catchlengthclass_03July2023_uncount[ , unique(paste(survey_id, sampling_method_abbrev))] %in% mi_statustrends_effort_16Mar2021[, paste(survey_id,sampling_method_abbrev)]]

mi_statustrends_effort_16Mar2021[survey_id == 4042]

mi_statustrends_catchlengthclass_03July2023_uncount[ survey_id == 4042, .N , .(species.1, sampling_method_abbrev) ]


#are there any surveys without any catch? Yes, 120 of them. (can we assume catch = zero there? Likely yes )
sum(!
      mi_statustrends_effort_16Mar2021[ , 
                                        unique(paste(survey_id, sampling_method_abbrev))
      ] %in%
      mi_statustrends_catch_16Mar2021_uncount[ ,
                                               unique(paste(survey_id, sampling_method_abbrev)) ,
      ]
)

mi_statustrends_catch_16Mar2021[ , summary(total_count.1) ,]

# and how many surveyX gears are not shown in the effort file? ZERO!                
sum(!mi_statustrends_catch_16Mar2021_uncount[ ,
                                              unique(paste(survey_id, sampling_method_abbrev)) ,
] %in%
  mi_statustrends_effort_16Mar2021[ , 
                                    unique(paste(survey_id, sampling_method_abbrev))
  ]

)
#this tells us we can skip expansion here. These no catch are already captured in the effort file

#merge catch files:                
names(mi_statustrends_catch_16Mar2021_uncount)
colnames(mi_statustrends_catchlengthclass_03July2023_uncount)


#set key columns
keycols <- c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev", "species.1", "ident")
setkeyv(mi_statustrends_catch_16Mar2021_uncount, keycols )
setkeyv(mi_statustrends_catchlengthclass_03July2023_uncount, keycols )

#merge together all catch data
mi_catch_merge <- merge(mi_statustrends_catch_16Mar2021_uncount, mi_statustrends_catchlengthclass_03July2023_uncount, by = keycols, all = T, suffixes = c("_catch", "_catchlengths"))


#merge effort into this

#set key columns
keycols <- c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev")
setkeyv(mi_catch_merge, keycols )
setkeyv(mi_statustrends_effort_16Mar2021, keycols )

#drop survey level info that will otherwise get duplicated upon  merge() (DONT DO THIS HERE, WILL LOSE DATA-- SEE data_coverage table)
data_coverage[ ,.N , .("effortNA" = is.na(effort_nrows), "catchlenNA" = is.na(catchlen_nrows))]
data_coverage[ ,.N , .("effortNA" = is.na(effort_nrows), "catchNA" = is.na(catch_nrows))]


#do merge
mi_catch_eff_merge <- merge(mi_catch_merge, mi_statustrends_effort_16Mar2021, by = keycols, all = T, suffixes = c("_mergedcatch", "_effort"))


#aged fish do not have a sampling method with them - we cannot directly attach an age to fish collected in a community survey
#here we will add aged fish as "extra" fish that do not have any effort associated with them 
aged_fish_join <- mi_statustrends_lenage_20May2021 %>% 
  #several records do not have a lake id - it would be impossible to cross walk, lets remove them
  mutate(lake_id = case_when(lake_id == "" ~ NA,
                             TRUE ~ lake_id)) %>% 
  filter(!is.na(lake_id)) %>% 
  mutate(sampling_method_abbrev = "unspecified",
         date.1_effort = dmy(date.1),
         date.1_effort = as.character(date.1_effort)
         ) %>% 
  rename(original_file_name.1_age = original_file_name.1,
         survey_type.1_effort = survey_type.1) %>% 
  select(-date.1,
         -file_type,
         -data_type) 

aged_fish_join %>% 
  group_by(lake_id) %>% 
  count() 

mi_catch_eff_merge %>% 
  group_by(original_file_name.1_catch,
           original_file_name.1_catchlengths,
           original_file_name.1) %>% 
  count()
#this just shows the various original files - effort file is in original file name.1

mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  full_join(aged_fish_join, 
            by = c("lake_id", 
                   "survey_id", 
                   "date.1_effort",
                   "sampling_method_abbrev",
                   "species.1",
                   "length.1",
                   "length_unit.1",
                   "jan2023_inventoried",
                   "file_number",
                   "file_status",
                   "state",
                   "source_contact",
                   "date_recieved",
                   "source_agency",
                   "new_file_name",
                   "targeted_or_standard",
                   "unique_row_key.1",
                   "survey_type.1_effort"),
            suffix = c("_full", "_aged"))
glimpse(mi_catch_eff_merge)

mi_catch_eff_merge %>% 
  filter(!is.na(age)) %>% 
  glimpse()

mi_catch_eff_merge %>% 
  group_by(original_file_name.1,
           original_file_name.1_catch,
           original_file_name.1_catchlengths,
           original_file_name.1_age) %>% 
  count()
#this actually works super slick, we now have aged fish as "supplemental" rows due to the fact we could not tie them to the actual sampling method
#as we progress down the script we will need to make sure that we call the correct columns and create a flag to remove this from cpe generation

#there are four originals files that we need to keep track of
#catch: catch data, catch inch group - found in original_file_name.1_catch and catchlength columns
#age: age clean - found within the "original_file_name.1_age" column
#effort: effort - found within the "original_file_name.1" column


#check the product:
colnames(mi_catch_eff_merge)

mi_catch_eff_merge[ str_detect(lake_name.1, "ike" ), .(count = .N, missinglengths = sum(is.na(length.1)), meanL = mean(length.1)), .(lake_name.1, lake_id, date.1_effort, date.1_mergedcatch, survey_id, sampling_method_abbrev, species.1) ]


#did we retain all of the surveys? Looks like 498 unique survey IDs, and both the product and input reflect this:
mi_catch_eff_merge[ , .N , .(survey_id)]
merge(merge(mi_statustrends_effort_16Mar2021[ , .( effort_nrows = .N) , survey_id], 
            mi_statustrends_catch_16Mar2021[ , .( catch_nrows = .N) , survey_id], all = T),
      mi_statustrends_catchlengthclass_03July2023[ , .( catchlen_nrows = .N) , survey_id ], all = T)


#here's all of our effort:
mi_catch_eff_merge[ , .N ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
#no catch data exist (or matched) for these data:
mi_catch_eff_merge[ is.na(species.1)  , .N ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
#no_taxa_found
mi_catch_eff_merge[   , nothing_caught  := is.na(species.1) ,  ]


#no effort data were submitted for these fish:
mi_catch_eff_merge[ is.na(date.1_effort)  , .N ,   c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]


#clean up the column names and tidy the data table up a bit                 

sort(colnames(mi_catch_eff_merge))                 

#county     
mi_catch_eff_merge[ is.na(county_mergedcatch)|is.na(county_effort) , .N ,   ]
mi_catch_eff_merge[ !(is.na(county_mergedcatch)&is.na(county_effort)) & county_mergedcatch != county_effort  , .N ,   ]# no cases where the county doesn't match
mi_catch_eff_merge[  , .N , .(is.na(county_mergedcatch), is.na(county_effort))  ]#there are some cases where we haven't got a county at all, otherwise the effort county covers all. 
mi_catch_eff_merge[  , county_mergedcatch := NULL]
setnames(mi_catch_eff_merge, "county_effort", "county")

#data_type
setnames(mi_catch_eff_merge, "data_type", "data_type_effort")

#date.1
mi_catch_eff_merge[ is.na(date.1_mergedcatch)|is.na(date.1_effort) , .N ,   ]
mi_catch_eff_merge[ !(is.na(date.1_mergedcatch)&is.na(date.1_effort)) & date.1_mergedcatch != date.1_effort  , .N ,   ]# no cases where the dates don't match
mi_catch_eff_merge[  , .N , .(is.na(date.1_mergedcatch), is.na(date.1_effort))  ]#there are some cases where we haven't got a date at all, otherwise the effort info covers all. 
mi_catch_eff_merge[  , date.1_mergedcatch := NULL]
setnames(mi_catch_eff_merge, "date.1_effort", "date.1")

#date recieved
setnames(mi_catch_eff_merge, "date_recieved", "date_recieved_effort")

#effort units
mi_catch_eff_merge[ is.na(effort_units.1_mergedcatch)|is.na(effort_units.1_effort) , .N ,   ]
mi_catch_eff_merge[ !(is.na(effort_units.1_mergedcatch)&is.na(effort_units.1_effort)) & effort_units.1_mergedcatch != effort_units.1_effort  , .N ,   ]# no cases where the units don't match
mi_catch_eff_merge[  , .N , .(is.na(effort_units.1_mergedcatch), is.na(effort_units.1_effort))  ]#we have efforts for all. slide into single column. 

mi_catch_eff_merge[is.na(effort_units.1_effort), .N , ]
mi_catch_eff_merge[is.na(effort_units.1_effort) , effort_units.1_effort := effort_units.1_mergedcatch , ]
mi_catch_eff_merge[ , effort_units.1_mergedcatch := NULL , ]
setnames(mi_catch_eff_merge, "effort_units.1_effort", "effort_units.1")

#filenumber
setnames(mi_catch_eff_merge, "file_number", "file_number_effort")

#state
mi_catch_eff_merge[ ,state := "Michigan"  ] 
mi_catch_eff_merge[ , `:=` (state_catch = NULL, state_catchlengths = NULL)  , ]

#total effort
mi_catch_eff_merge[total_effort_1_effort != total_effort_1_mergedcatch, .N,  ]
#plot(total_effort_1_effort ~ total_effort_1_mergedcatch, data = mi_catch_eff_merge  )
#abline(1,0)

#effort vals
mi_catch_eff_merge[ total_effort_1_effort != total_effort_1_mergedcatch , .N , .(total_effort_1_mergedcatch, total_effort_1_effort)]
#I think that the merged catch values were assigned to indiv fish (like "this fish was caught in ONE net lift") and the effort file has survey X gear total efforts
mi_statustrends_catchlengthclass_03July2023[ , summary(total_effort_1) , ] 
mi_statustrends_catchlengthclass_03July2023[total_effort_1 > 1 , summary(total_count.1), sampling_method_abbrev]
# mi_statustrends_catch_16Mar2021[ , summary(total_effort_1.1) , ]    #this won run b/c no col for effort in that       
mi_statustrends_effort_16Mar2021[ , summary(total_effort_1) ,]          
# well--- I don't know what to make of all this, but for now I'll be keeping both of these "total_effort" variables, and leaning on the one originating in the effort file



#year

mi_catch_eff_merge[ year_effort != year_mergedcatch , ,]
mi_catch_eff_merge[ , .N , .(is.na(year_effort), is.na(year_mergedcatch))]
mi_catch_eff_merge[is.na(year_effort), year_effort := year_mergedcatch , ]
mi_catch_eff_merge[ ,  year_mergedcatch := NULL , ]
setnames(mi_catch_eff_merge, "year_effort", "year")


# most of this is waste-of-time junk. Let's move the big ones left and leave this mess hang out there to the right.
notgarbage <-  c("county","lake_id", "lake_name.1", "date.1", "year", "survey_id",  #survey 
                 "sampling_method_abbrev", "total_effort_1_effort", "effort_units.1", "nothing_caught",  #gear
                 "species.1", "ident", "length.1", "length_unit.1", "ident_l" #fish
                 )

setcolorder(mi_catch_eff_merge, notgarbage)


#expand these data to cover all interested species in each surveyXgear

#check behavior now:
mi_catch_eff_merge[ species.1 == "WAE" , .N  , c("lake_name.1", "lake_id", "survey_id", "sampling_method_abbrev") ]
#we can see that to gen a catch or CPUE dataset we can cast wide (like we did in MN)

#generate a species obs matrix
#clean dates:
mi_catch_eff_merge[ , unique(date.1) , ]

#execute
mi_catch_eff_merge[ , date_clean := as.IDate(date.1) ,]
mi_catch_eff_merge[ , summary(date_clean) , ]
mi_catch_eff_merge[ is.na(date_clean) , .N , .(survey_id, lake_name.1)] #missing effort data here, thus the gap


#tag codes with "taxon"
mi_catch_eff_merge[ , species.1 := paste("taxon_",species.1, sep = "")  ,]

#we called this "wide complete" in MN
wide_complete <- dcast(mi_catch_eff_merge[ ,.N , by = c("county","lake_id", "lake_name.1", "date.1", "year", "survey_id",  #survey 
                                                        "sampling_method_abbrev", "total_effort_1_effort", "effort_units.1", "nothing_caught", 
                                                        "species.1")
                                           ] ,
                       ... ~ species.1 ,
                       value.var = "N",
                       fill = 0)

wide_complete[ , c("county","lake_id", "lake_name.1", "date.1", "year", "survey_id",  #survey 
                   "sampling_method_abbrev", "total_effort_1_effort", "effort_units.1", "taxon_WAE") , ]

wide_complete[taxon_NA >0]

# now add in an effort identifier column:
            mi_catch_eff_merge[ , effort_ident := .GRP ,.(county,lake_id, lake_name.1, date.1, year, survey_id,  #survey 
                                                        sampling_method_abbrev, total_effort_1_effort, effort_units.1, nothing_caught) ]            
# now use Denver Links cleanup of these:
#changing species names to standard format                       
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  #renaming species abbreviations column - changed to common name in the following step
  rename(species.abbrev = species.1) %>% 
  #agency species code updated with common name
  mutate(species.1 = case_when(species.abbrev == "taxon_BCR" ~ "black_crappie",
                             species.abbrev == "taxon_BLG" ~ "bluegill",
                             species.abbrev == "taxon_CIS" ~ "cisco",
                             species.abbrev == "taxon_LMB" ~ "largemouth_bass",
                             species.abbrev == "taxon_NOP" ~ "northern_pike",
                             species.abbrev == "taxon_SMB" ~ "smallmouth_bass",
                             species.abbrev == "taxon_WAE" ~ "walleye",
                             species.abbrev == "taxon_YEP" ~ "yellow_perch",
                             species.abbrev == "taxon_NA" ~ NA,
                             TRUE ~ species.abbrev)) %>% 
  #Gear type code updated with spelled-out common name
  mutate(sampling_method = case_when(sampling_method_abbrev == "BOOMSHK" ~ "boomshocking",
                                            sampling_method_abbrev == "GLGNET" ~ "great_lakes_gill_net",
                                            sampling_method_abbrev == "IGNET" ~ "inland_gill_net",
                                            sampling_method_abbrev == "LMFYKE" ~ "large_mesh_fyke_net",
                                            sampling_method_abbrev == "SEINE" ~ "seine",
                                            sampling_method_abbrev == "SMFYKE" ~ "small_mesh_fyke_net",
                                            sampling_method_abbrev == "TRAPNET" ~ "trap_net",
                                     sampling_method_abbrev == "unspecified" ~ "unspecified")) %>% 
  #unit length 
  mutate(length_unit.1 = case_when(length_unit.1 == "col_name_Inch_Group" ~ "inch_group",
                                   length_unit.1 == "col_name_LENGHT_IN" ~ "inches",
                                   is.na(length.1) ~ NA,
                                   TRUE ~ length_unit.1)) %>% 
  #effort unit 
  mutate(effort_units.1 = case_when(effort_units.1 == "HAULS" ~ "hauls",
                                    effort_units.1 == "MINUT" ~ "minutes",
                                    effort_units.1 == "LIFTS" ~ "lifts")) %>%
  #original file name for effort found in the original_file_name.1 spot 
  rename(original_file_name.1_effort = original_file_name.1) %>% 
  #Twin lake (survey id 4042) does not have effort info so looks lake info, from the MSU team we know that the lake id is 48-28. This will allow us to connect to NHDHRID and other lake info
  mutate(lake_id = case_when(survey_id == "4042" ~ "48-28",
                             TRUE ~ lake_id)) %>% 
  #selects for columns to be used during analysis - limits memory usage and creates more clarity
  #effort files for survey type, lat/long, and target species contained more data than the merged catch files
  select(state, county, lake_id, lake_name.1, date.1, year, survey_type.1_effort, survey_id, lat_unspec_effort, lon_unspec_effort, sampling_method, sampling_method_abbrev, target_species_effort, species.1, species.abbrev, length.1, length_unit.1, total_effort_1_effort, effort_units.1, effort_ident, nothing_caught, original_file_name.1_catch,original_file_name.1_catchlengths,original_file_name.1_effort, original_file_name.1_age, age, aging_structure.1)         

mi_catch_eff_merge %>% 
  group_by(original_file_name.1_catch, 
           original_file_name.1_catchlengths, 
           original_file_name.1_effort, 
           original_file_name.1_age) %>% 
  count()
#this shows good original file separation - aged fish are only from the aged fish file and do not have effort
#there is one survey that has file records but does not have any effort

mi_catch_eff_merge %>% 
  group_by(original_file_name.1_catch, 
           original_file_name.1_catchlengths, 
           original_file_name.1_effort, 
           original_file_name.1_age) %>% 
  summarise(no_lengths = sum(is.na(length.1)),
            has_lengths = sum(!is.na(length.1)))
#all fish records that do not associate with the inchgrp clean original file do not have lengths 

mi_catch_eff_merge %>% 
  filter(is.na(length.1)) %>% 
  group_by(year, original_file_name.1_catch ,original_file_name.1_catchlengths, original_file_name.1_age) %>% 
  count() %>% 
  print(n = nrow(.))
#this just shows that all na lengths come from a no catchlength df and are not aged fish

mi_catch_eff_merge %>% 
  filter(!is.na(length.1)) %>% 
  distinct(length.1, length_unit.1, original_file_name.1_age, original_file_name.1_catchlengths) %>% 
  print(n = nrow(.))
#all aged fish were measured more finely than to the nearest inch grouping 

mi_catch_eff_merge %>% 
  group_by(is.na(age), length_unit.1) %>% 
  count()
#perfect, we see here that if a fish is aged that it got a specific length but all other fish are measured in inch bins 

#now we need to fill aged fish survey level data with more info where we can
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  group_by(lake_id) %>% 
  mutate(
    county = if (all(is.na(county))) county else first(na.omit(county)),
    lake_name.1 = if (all(is.na(lake_name.1))) lake_name.1 else first(na.omit(lake_name.1)),
    lat_unspec_effort = if (all(is.na(lat_unspec_effort))) lat_unspec_effort else first(na.omit(lat_unspec_effort)),
    lon_unspec_effort = if (all(is.na(lon_unspec_effort))) lon_unspec_effort else first(na.omit(lon_unspec_effort))
  ) %>% 
  ungroup()

mi_catch_eff_merge %>% 
  filter(!is.na(age)) %>% 
  group_by(is.na(county),
           is.na(lake_name.1),
           is.na(lat_unspec_effort),
           is.na(lake_id)) %>% 
  count()
#we were able to recover lake level info for all lake ids from the aged fish file

mi_catch_eff_merge %>% 
  group_by(lake_id) %>% 
  distinct(county, lake_name.1, lat_unspec_effort) %>% 
  group_by(lake_id) %>% 
  count() %>% 
  filter(n >1)
#this just shows that all lake_ids in the aged file were attached to the correct lake id

mi_catch_eff_merge %>% 
  group_by(is.na(age)) %>% 
  summarise(na_lake_id = sum(is.na(lake_id))) 
#no na lake ids


local_to_nhdhr(mi_catch_eff_merge %>% filter(!is.na(lake_id)), from_colname = "lake_id", states = "mi") %>%
  count(nhdhr.id)

mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  local_to_nhdhr(from_colname = "lake_id", states = "mi")

#If there are NAs in the lake Ids you feed into these local to NHD functions, you'll end up raking a ton of extra nhdhr vals from the NA local ID column. 

#these are the unmatched lake_ids that we're left with.
mi_catch_eff_merge <- as.data.table(mi_catch_eff_merge)
mi_catch_eff_merge[is.na(nhdhr.id), .N , lake_id ]
mi_catch_eff_merge %>% 
  group_by(is.na(age), is.na(nhdhr.id)) %>% 
  count()

#do we need to retain more date columns?
mi_statustrends_catch_16Mar2021_uncount %>% 
  group_by(survey_id, date.1) %>% 
  count()

mi_catch_eff_merge %>% 
  group_by(survey_id, effort_ident, sampling_method, date.1) %>% 
  count() 

#matching gear schema across states for the hive
#here i use the gears xwalk found in the google drive crosswalk folder
gear_xwalk <- read_csv("gears_by_state.csv") %>% 
  filter(state == "Michigan") %>% 
  rename(sampling_method_agency = gear_2) %>% 
  select(sampling_method_agency, 
         sampling_method_simple,
         sampling_method_1,
         sampling_method_2) %>% 
  rename(sampling_method = sampling_method_1)

mi_catch_eff_merge %>% 
  group_by(sampling_method, sampling_method_abbrev) %>% 
  count()
#looks like I will use the sampling method as the crosswalk

mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  rename(sampling_method_agency = sampling_method) %>% 
  left_join(gear_xwalk)

mi_catch_eff_merge %>% 
  group_by(sampling_method_agency, sampling_method_abbrev, sampling_method_simple, sampling_method, sampling_method_2) %>% 
  count()

#adding leading tag to nhdhr_id
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  mutate(nhdhr.id = case_when(!is.na(nhdhr.id) ~ paste0("nhdhr_", nhdhr.id),
                              TRUE ~ NA))

#adding flags where they are needed
effort_flag_xwalk <- mi_catch_eff_merge %>% 
  distinct(survey_id, sampling_method_agency, total_effort_1_effort) %>% 
  mutate(flag = case_when(survey_id == "4042" ~ "no effort data",
                          TRUE ~ NA)) %>% 
  group_by(sampling_method_agency) %>% 
  mutate(mean_effort = mean(total_effort_1_effort, na.rm = TRUE),
         sd_effort = sd(total_effort_1_effort, na.rm = TRUE),
         z_score = (total_effort_1_effort - mean_effort) / sd_effort,
    flag = case_when(total_effort_1_effort <= 0 ~ "invalid effort (zero or negative)",
                     z_score > 10 ~ "high effort",
                     TRUE ~ flag)) 
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  left_join(effort_flag_xwalk, by = c("survey_id",
                                      "sampling_method_agency",
                                      "total_effort_1_effort"))

#adding lat and lon centroids

#lat and lon info coming from usgs data repo (https://www.sciencebase.gov/catalog/item/6206d3c2d34ec05caca53071) lake metadata file
lat_lon_usgs <- read_csv("lake_metadata.csv") %>% 
  filter(state == "MI") %>% 
  select(site_id,
         centroid_lon,
         centroid_lat) %>% 
  mutate(nhdhr.id = sub("^nhdhr_", "", site_id))

mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  #adds lats/lons to data using nhdid
  left_join(lat_lon_usgs, "nhdhr.id") %>%
  #not all lakes have nhdids and/or there is no usgs lat/lon for them
  #here we take the usgs centroid where it exists and fill the lakes that do not have that data with survey level info from the agency 
  mutate(latitude_lake_centroid = lat_unspec_effort,
         longitude_lake_centroid = lon_unspec_effort,
         latitude_lake_centroid = case_when(is.na(latitude_lake_centroid) ~ centroid_lon,
                                            TRUE ~ latitude_lake_centroid),
         longitude_lake_centroid = case_when(is.na(longitude_lake_centroid) ~ centroid_lon,
                                             TRUE ~ longitude_lake_centroid))
rm(lat_lon_usgs)
#there is one survey_id (4042) that has fish but no effort, lake level info is retained by the effort file. Thus, we are not able to generate a lat/lon for that survey (three total effort idents in one lake)


msu_crosswalk <- read_csv("MGLP_FISH_LAKES_12Aug24.csv") %>% 
  filter(STATE == "MI") %>% 
  select(STATE_ID,
         NHDHR_ID) %>% 
  rename(lake_id = STATE_ID,
         nhdhr_id_msu = NHDHR_ID)

mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  left_join(msu_crosswalk, by = "lake_id")

mi_catch_eff_merge %>%
  distinct(lake_id, .keep_all = T) %>%
  select(lake_id, lake_name.1, nhdhr.id, nhdhr_id_msu) %>% 
  group_by(is.na(nhdhr.id), is.na(nhdhr_id_msu)) %>% 
  count()

mi_catch_eff_merge %>%
  distinct(lake_id, .keep_all = T) %>%
  select(lake_id, lake_name.1, nhdhr.id, nhdhr_id_msu) %>% 
  filter(!is.na(nhdhr.id)) %>% 
  filter(!is.na(nhdhr_id_msu)) %>% 
  mutate(nhdhr.match = case_when(nhdhr.id == nhdhr_id_msu ~ T,
                                 T ~ F)) %>% 
  filter(nhdhr.match == F)
#we pick up 2 more nhdhr_ids with the msu cross walk, but why does the msu crosswalk not have all of our lakes?
#Gut lake has a one number digit difference between mwlax package and msu crosswalk

#here we take nhdhr ids 1.) generated by the USGS crosswalk 2.) extras gathered by the msu team
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  mutate(nhdhr.id = case_when(is.na(nhdhr.id) ~ nhdhr_id_msu,
                              TRUE ~ nhdhr.id))

mi_catch_eff_merge %>%
  distinct(lake_id, .keep_all = T) %>%
  select(lake_id, lake_name.1, nhdhr.id, nhdhr_id_msu) %>% 
  group_by(is.na(nhdhr.id), is.na(nhdhr_id_msu)) %>% 
  count()
#we can now see that the 2 lakes from the msu crosswalk are added to the false false world

#filling missing lake info from other places in the data
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  group_by(lake_id) %>% 
  mutate(county = case_when(is.na(county) ~ coalesce(county, first(na.omit(county))),
                            TRUE ~ county),
         lat_unspec_effort = case_when(is.na(lat_unspec_effort) ~ coalesce(lat_unspec_effort, first(na.omit(lat_unspec_effort))),
                                       TRUE ~ lat_unspec_effort),
         lon_unspec_effort = case_when(is.na(lon_unspec_effort) ~ coalesce(lon_unspec_effort, first(na.omit(lon_unspec_effort))),
                                       TRUE ~ lon_unspec_effort),
         latitude_lake_centroid = case_when(is.na(latitude_lake_centroid) ~ coalesce(latitude_lake_centroid, first(na.omit(latitude_lake_centroid))),
                                            TRUE ~ latitude_lake_centroid),
         longitude_lake_centroid = case_when(is.na(longitude_lake_centroid) ~ coalesce(longitude_lake_centroid, first(na.omit(longitude_lake_centroid))),
                                             TRUE ~ longitude_lake_centroid)
           )

#adding flags for unlikely lengths/weights
length_weight_flags_1 <- mi_catch_eff_merge %>% 
  filter(!is.na(species.1)) %>% 
  group_by(species.1) %>% 
  mutate(mean_length = mean(length.1, na.rm = TRUE),
         sd_length = sd(length.1, na.rm = TRUE),
         z_score_length = (length.1 - mean_length) / sd_length,
         flag = case_when(z_score_length >= 10 | z_score_length <= -10 ~ paste("unlikely length", ";", coalesce(flag, "")),
                          TRUE ~ coalesce(flag, "")),
         flag = case_when(length.1 == 0 ~ paste("length reported as 0", ";", coalesce(flag, "")),
                          TRUE ~ coalesce(flag, "")),
         flag = na_if(flag, "")) %>% 
  select(survey_id,
         effort_ident,
         species.1,
         length.1,
         mean_length,
         z_score_length,
         flag) %>% 
  filter(!is.na(flag)) %>% 
  distinct()

mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  select(-flag) %>% 
  left_join(length_weight_flags_1, by = c("survey_id", 
                                          "effort_ident", 
                                          "species.1", 
                                          "length.1"), relationship = "many-to-one")
rm(length_weight_flags_1)

#adding flag to aged fish that are "extra"
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  mutate(flag = case_when(!is.na(age) ~ paste("likely duplicate fish record retained for length-age", ";", coalesce(flag, "")),
                          TRUE ~ coalesce(flag, "")),
         flag = na_if(flag, "")
         )

mi_catch_eff_merge %>% 
  group_by(flag) %>% 
  count() %>% 
  print(n = nrow(.))

#cleaning up length columns
mi_catch_eff_merge <- mi_catch_eff_merge %>% 
  mutate(length_1 = case_when(!is.na(age) ~ length.1,
                              TRUE ~ NA),
         length_unit_1 = case_when(!is.na(age) ~ length_unit.1,
                                   TRUE ~ NA),
         length_bin = case_when(is.na(age) & !is.na(length.1) ~ paste0(length.1, "-", length.1+0.99),
                                TRUE ~ NA),
         length_bin_unit = case_when(!is.na(length_bin) ~ "inches",
                                     TRUE ~ NA)
         )
mi_catch_eff_merge %>% 
  group_by(is.na(length_1),
           length_unit_1,
           is.na(age),
           length_bin,
           length_bin_unit) %>% 
  count() %>% 
  print(n = nrow(.))

mi_catch_eff_merge %>% 
  group_by(is.na(length.1)) %>% 
  count()

mi_catch_eff_merge %>% 
  group_by(aging_structure.1) %>% 
  count()

#cleaning up the age structure
mi_catch_eff_merge <- mi_catch_eff_merge %>%
  mutate(aging_structure_1 = str_trim(aging_structure.1),
         aging_structure_1 = str_to_lower(aging_structure.1),
         aging_structure_1 = na_if(aging_structure_1, "")) %>% 
  filter(aging_structure_1 != "length-frequency" | is.na(aging_structure_1))

mi_catch_eff_merge %>% 
  group_by(aging_structure_1) %>% 
  count()

#matching to schema
mi_data <- mi_catch_eff_merge %>% 
  ungroup() %>% 
  mutate(lake_name = lake_name.1,
         date_survey = as.Date(date.1),
         date_total_effort_ident = as.Date(date.1),
         date_sub_effort_ident = as.Date(NA),
         date_sample = as.Date(NA),
         year = year(date.1),
         month = month(date.1),
         survey_id = as.character(survey_id),
         survey_type = survey_type.1_effort,
         survey_type_2 = as.character(NA),
         survey_type_3 = as.character(NA),
         survey_type_4 = as.character(NA),
         gear_data_notes = as.character(NA),
         target_species = target_species_effort,
         #target_species_2 = as.character(NA),
         total_effort_ident = as.character(effort_ident),
         total_effort_1 = total_effort_1_effort,
         total_effort_2 = as.numeric(NA),
         #total_effort_3 = as.numeric(NA),
         total_effort_1_units = effort_units.1,
         total_effort_2_units = as.character(NA),
         #total_effort_3_units = as.character(NA),
         total_effort_nothing_caught = nothing_caught,
         water_temp = as.numeric(NA),
         water_temp_units = as.character(NA),
         water_clarity = as.numeric(NA),
         water_clarity_units = as.character(NA),
         lat_start = as.numeric(NA),
         lat_end = as.numeric(NA),
         lon_start = as.numeric(NA),
         lon_end = as.numeric(NA),
         site_id = as.character(NA),
         sub_effort_ident = as.character(NA),
         sub_effort_1 = as.numeric(NA),
         sub_effort_1_units = as.character(NA),
         sub_effort_2 = as.numeric(NA),
         sub_effort_2_units = as.character(NA),
         sub_effort_nothing_caught = as.logical(NA),
         #aging_structure_2 = as.character(NA),
         weight_1 = as.numeric(NA),
         weight_unit_1 = as.character(NA),
         batch_weight = as.character(NA),
         batch_weight_unit = as.character(NA),
         sex = as.character(NA),
         age_class = as.character(NA),
         ind_fish_ident = as.character(NA),
         lakesize = as.numeric(NA),
         lakesize_units = as.character(NA),
         #area_group = as.character(NA),
         lat_unspec = lat_unspec_effort,
         lon_unspec = lon_unspec_effort,
         waterbody_type = as.character(NA),
         location_notes_1 = as.character(NA),
         notes_1 = as.character(NA),
         obs_id = as.character(row_number())) %>% 
   unite("original_file_names", c(original_file_name.1_catch,
                                      original_file_name.1_catchlengths,
                                      original_file_name.1_effort,
                                  original_file_name.1_age), 
                                      remove = T, 
                                      na.rm = T,
         sep = " ") %>% 
  select(state,
         county,
         lake_name,
         lake_id,
         nhdhr.id,
         latitude_lake_centroid,
         longitude_lake_centroid,
         date_survey,
         date_total_effort_ident,
         date_sub_effort_ident,
         date_sample,
         year,
         month,
         survey_id,
         survey_type,
         survey_type_2,
         survey_type_3,
         survey_type_4,
         sampling_method_simple,
         sampling_method,
         sampling_method_2,
         gear_data_notes,
         target_species,
         #target_species_2,
         total_effort_ident,
         total_effort_1,
         total_effort_2,
         #total_effort_3,
         total_effort_1_units,
         total_effort_2_units,
         #total_effort_3_units,
         total_effort_nothing_caught,
         water_temp,
         water_temp_units,
         water_clarity,
         water_clarity_units,
         lat_start,
         lon_start,
         lat_end,
         lon_end,
         site_id,
         sub_effort_ident,
         sub_effort_1,
         sub_effort_1_units,
         sub_effort_2,
         sub_effort_2_units,
         sub_effort_nothing_caught,
         species.1,
         length_1,
         length_unit_1,
         length_bin,
         length_bin_unit,
         age,
         aging_structure_1,
         #aging_structure_2,
         weight_1,
         weight_unit_1,
         batch_weight,
         batch_weight_unit,
         sex,
         age_class,
         flag,
         original_file_names,
         ind_fish_ident,
         lakesize,
         lakesize_units,
         #area_group,
         lat_unspec,
         lon_unspec,
         waterbody_type,
         location_notes_1,
         notes_1,
         obs_id)
glimpse(mi_data)

mi_data <- mi_data %>% 
  clean_names()
glimpse(mi_data)
```                        
                        
 
# Review & QC datasets
```{r}
mi_data %>% 
  filter(survey_id == "2446") %>% 
  group_by(total_effort_ident,
           survey_id,
           sampling_method_2,
           date_total_effort_ident,
           flag) %>% 
  summarise(aged_fish = sum(!is.na(age))) 
#here we can see that aged fish get a different total effort ident within a survey id 
#this isn't a problem, it is another reminder that users need to filter out ages if they want cpe

mi_data %>% 
  distinct(total_effort_1, .keep_all = T) %>% 
  group_by(lake_name, lake_id, survey_id, total_effort_1_units) %>% 
  count()

#effort per survey type?
mi_data %>% 
  filter(!is.na(total_effort_1)) %>% 
  group_by(lake_name, lake_id, survey_id, total_effort_1, total_effort_1_units) %>% 
  summarise(n = n()) %>% 
  summarise(effort = sum(total_effort_1), counts = sum(n), grandCPUE = sum(n)/sum(total_effort_1))
        
                        
                        #effort per survey type (Walleye ONLY)?
mi_data %>% 
  filter(!is.na(total_effort_1) & species_1 == "walleye") %>% 
  group_by(lake_name, lake_id, survey_id, total_effort_1, total_effort_1_units) %>% 
  summarise(n = n()) %>% 
  summarise(effort = sum(total_effort_1), counts = sum(n), grandCPUE = sum(n)/sum(total_effort_1))
                        
                        
                        
#how many Walleye in surveys where we had effort data?
mi_data %>% 
  group_by(sampling_method) %>% 
  summarise(walleye = sum(species_1 == "walleye", na.rm = T))

mi_data %>% 
  group_by(species_1, total_effort_nothing_caught) %>% 
  count()
                        
                        
#whats the effort look like?
mi_data %>% 
  group_by(total_effort_1) %>% 
  count() %>% 
  print(n = nrow(.))
                        
                        # data coverage
                        # how many surveys were we missing effort data for? One survey, 3 gears. Survey 4042 on Twin Lake
mi_data %>% 
  filter(is.na(total_effort_1)) %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  group_by(lake_name, survey_id, sampling_method, total_effort_1) %>% 
  count() %>% 
  print(n = nrow(.))
                        
                        
                        # how many surveys were we missing catch data from?
                        # how many surveys missing catchlength for?
mi_data %>% 
  group_by(original_file_names) %>% 
  count()

mi_data %>% 
  filter(!(grepl("mi_snt_catch_data_mar2021", original_file_names))) %>% 
  count()

mi_data %>% 
  summarise(catchNA = sum(!(grepl("mi_snt_catch_data_mar2021", original_file_names))),
            catchlengthNA = sum(!(grepl("mi_snt_catch_inchgrp_clean_0722", original_file_names))),
            effortNA = sum(!(grepl("mi_snt_effort_data_mar2021", original_file_names))))

#how is the state name? 
mi_data %>% 
  group_by(state) %>% 
  count()

mi_data %>% 
  group_by(sampling_method_simple, sampling_method, sampling_method_2) %>% 
  count()

mi_data %>% 
  filter(survey_id == "4042") %>% 
  glimpse()

mi_data %>% 
  group_by(flag) %>% 
  count()

mi_data %>% 
  group_by(is.na(age)) %>% 
  count()

mi_data %>% 
  group_by(total_effort_nothing_caught) %>% 
  count()

mi_data %>% 
  group_by(is.na(length_1),
           length_unit_1,
           is.na(age),
           length_bin,
           length_bin_unit) %>% 
  count() %>% 
  print(n = nrow(.))

mi_data %>% 
  group_by(is.na(age), aging_structure_1) %>% 
  count()

mi_data %>% 
  group_by(original_file_names) %>% 
  count()

mi_data %>% 
  group_by(total_effort_ident, total_effort_1) %>% 
  count() %>% 
  group_by(total_effort_ident) %>% 
  count() %>% 
  filter(n >1)

mi_data %>% 
  group_by(length_unit_1, weight_unit_1, total_effort_1_units, total_effort_2_units, length_bin_unit) %>% 
  count()
```

# Import/Export files
```{r}


#save to disk:

# saveRDS(mi_catch_eff_merge, file = "Data_and_Scripts\\Data\\output\\mi_flat_effort_indivfish_merge.rds")
# mi_catch_eff_merge <- readRDS(file = "Data_and_Scripts\\Data\\output\\mi_flat_effort_indivfish_merge.rds")




mi_data <- as_arrow_table(mi_data)

write_dataset(dataset = mi_data, path = "Data_and_Scripts/Data/output/mi_file_arrow")

mi_data <- open_dataset("Data_and_Scripts/Data/output/mi_file_arrow")

glimpse(mi_data)
```

