---
title: "MN_Flat_File_Aggregation"
author: "Holly Kundel & Mike Verhoeven"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Preamble
updated 11/29
To Do:
CHECK: Historical WAE survey duplication
  - check on outcome of fixes (section name: sleuth out the MN duplicated data issues)
1. where gear notes marked with dippers, bring back dipper # into end of gear desc.
2. Consider grabbing the mesh var?
3. Daylight EFing (gear data notes 2 - keep it around for filtering)

4. Line 229 might offer a key to the large lakes missing data issue. Had a "total.count" val for those, 
  





libraries
```{r}
library(arrow)
library(readr)
library(tidyverse)
library(stringr)
library(data.table)
library(janitor)
library(tidyr)
library(lubridate)
library(bit64)
library(ggplot2)
library(mwlaxeref)

options(scipen = 999)
```




# Load Data

* note depending on your local settings, file paths need correction to match local GDrive letter

```{r}
##build functions  
remove_unnecessary_suffixes <- function(dt) {
  # Identify columns with numeric suffixes
  numeric_suffix_cols <- grep("\\.\\d+$", names(dt), value = TRUE)
  
  # Create a list to store prefixes
  prefixes <- unique(sub("\\.\\d+$", "", numeric_suffix_cols))
  
  # Remove unnecessary numeric suffixes
  for (prefix in prefixes) {
    cols <- grep(paste0("^", prefix, "\\.\\d+$"), names(dt), value = TRUE)
    if (length(cols) == 1) {
      setnames(dt, cols, sub("\\.\\d+$", "", cols))
    }
  }
  
  return(dt)
}

remove_unnecessary_suffixes_2 <- function(dt) {
  # Identify columns with numeric suffixes
  numeric_suffix_cols <- grep("\\_\\d+$", names(dt), value = TRUE)
  
  # Create a list to store prefixes
  prefixes <- unique(sub("\\_\\d+$", "", numeric_suffix_cols))
  
  # Remove unnecessary numeric suffixes
  for (prefix in prefixes) {
    cols <- grep(paste0("^", prefix, "\\_\\d+$"), names(dt), value = TRUE)
    if (length(cols) == 1) {
      setnames(dt, cols, sub("\\_\\d+$", "", cols))
    }
  }
  
  return(dt)
}

#generate a file list to import
files_list <- list.files(path = "D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data", pattern = ".+\\.csv") #grabs only.csv files
files_list

#object for use in loop (simple length of file list)
n <- length(files_list)

for(i in 1:n) {
  #i = 3
  outer_break <- FALSE# clean up so that break tool will refresh
  
  filei <- word(gsub(".csv","", files_list[i]), start = -1, sep = fixed("/"))
  #this does those two steps in one package
  assign(filei ,
          fread(paste0("D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/MN_Data/mn_raw_disaggregated_data/",
                                          files_list[i])))
  
  # if the file is a crosswalk, do not rename anything, just loop to the confirm import line
  if(str_detect(filei, "crosswalk")) {  #confirm import of files:  
    print(paste(filei ,"added to workspace" ))  
    #confirm import of files:  
    print(paste(i ,"files added to workspace" )) ; next}
  
  
  # note we want to review a sorted list of column names to check misspelling etc.
  # we still need to use the columns with names like col_name_length_in, or known_units
  
  
  cde %>% # call data explainer file
    filter(`new_file_name`== filei)%>% #keep only the row relevant to this file
    select_if(~ !any(is.na(.))) %>% 
    data.table::transpose(keep.names = "newname") %>% 
    rename("oldname" = V1) %>% 
    assign("names", ., envir = .GlobalEnv)
  
  #see if any column names will not have a match! 
  # IF any pop FALSE, force stop and revist of data explainer ()
  # - e.g., named something "total catch" when actual column name was "total_catch"
  print(
    cbind(colnames(get(filei)),
          colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]
    )
  )
  
  
  # break the loop if the current file has column names not in the data explainer
  # if (all(cbind(colnames(get(filei)),  colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ])[,2]) == FALSE ) break
  if (all(colnames(get(filei)) %in% names[ !str_detect(newname,"unique_row_key"), oldname, ]) == FALSE ) {
    warning(paste("Warning: Import renaming failed at file", filei))
    outer_break <-  TRUE
    break}
  
  
  # append old col names into new "notes" columns:
  get(filei)[ , (names[ str_detect(newname, "notes") , oldname   ,  ]) := Map(paste, colnames(.SD), .SD, sep = ':') , .SDcols =  names[ str_detect(newname, "notes") , oldname   ,  ] ]
  
  #now rename that file's colnames
  setnames(get(filei), colnames(get(filei)), names[!str_detect(newname,"unique_row_key")] [match(names(get(filei)),names[!str_detect(newname,"unique_row_key"),oldname]), newname] )
  
  #append all other data from data explainer
  unusedbits <- 
    data.table(
      matrix(
        rep(names[ !newname %in% colnames(get(filei)) , oldname , ],
            each = nrow(get(filei))
        ),
        nrow = nrow(get(filei)),
        dimnames = list(rep(NA,nrow(get(filei))),
                        names[ !newname %in% colnames(get(filei)) , newname , ])
        )
      )
  
  #add all not yet used columns from data explainer:
  get(filei)[ , (names[ !newname %in% colnames(get(filei)) , newname , ]) := unusedbits[] ]

  rm(names, unusedbits)
  
  
  #remove the unneeded suffixes from data
  assign(filei, remove_unnecessary_suffixes_2(remove_unnecessary_suffixes(get(filei))))
  
  #confirm import of files:  
  print(paste(filei ,"added to workspace" ))  
  #confirm import of files:  
  print(paste(i ,"files added to workspace" )) 

  
} 
if (outer_break) {print("Data import issue");rm(outer_break)
  } else {
  #confirm import of files:  
  print(paste(i ,"files added to workspace" ))
  #confirm import of files:  
  print(paste(n-i ,"remaining to be added" )) 
}
  
  
```


# Effort

```{r}

# effort dataset has a unique key in the combo of (lake_id, date.2(survey date), gear, survey type)
mn_effort_18aug2023[          , .N , .(lake_id, date.1, sampling_method, survey_type) ]

#note that there is a component count column in here that seems like it's related to effort, but not exactly clear to me:
mn_effort_18aug2023[ , summary(as.numeric(gsub("COMPONENT_COUNT:","",gear_data_notes.2))) ,]
mn_effort_18aug2023[ , hist(as.numeric(gsub("COMPONENT_COUNT:","",gear_data_notes.2)), breaks = 100) ,]


# we have two total effort cols, one is EF seconds, which I think is redundant to the main effort column:
mn_effort_18aug2023[ , total_effort_2 := gsub("EF_SECONDS:", "" , total_effort_2), ]
mn_effort_18aug2023[ total_effort_2 == "NA" , total_effort_2 := NA  ,]
mn_effort_18aug2023[  , total_effort_2 := as.numeric(total_effort_2) ,]


mn_effort_18aug2023[ , .N , .("te2NA" = is.na(total_effort_2), "te1NA" = is.na(total_effort_1))] # any cases where all dat in total.effort.2
#NOPE

#here we can see that ef time is essentially covered by the total effort 1 column (and probably more complete in that column)
plot(mn_effort_18aug2023[ !is.na(total_effort_2) , total_effort_2,]/3600~ mn_effort_18aug2023[ !is.na(total_effort_2) , total_effort_1 ,])
#what about the one's where they don't jive?
mn_effort_18aug2023[ round(total_effort_2/3600, 2) != total_effort_1, plot(total_effort_2/3600~total_effort_1), ]
abline(0,1)

#we don't need that extra total eff column
mn_effort_18aug2023[ , total_effort_2 := NULL , ]

#the DNR sent along two values for counts, one where they count only cases where CPUE was marked yes in the indiv fish data and one count including only where cpue was marked no in the indiv fish data

mn_effort_18aug2023[total_count.2>0 , .(total_count.1,total_count.2) , ]
mn_effort_18aug2023[ , plot(total_count.1~total_count.2) , ]

#are there any effort data with NO associated count (i.e., nothing caught)? 
mn_effort_18aug2023[   , .N , .("tc1_0" = total_count.1 == 0, "tc2_0" = total_count.2 == 0) ]
#NOPE

# Crazy that there are "no zeros". However, because these data are gear level, this is agg'd across species so relatively useless.

#drop these columns
mn_effort_18aug2023[ , `:=` ("total_count.1" = NULL,"total_count.2" = NULL) , ]


#fix up dates
mn_effort_18aug2023[ , date_clean :=  as.IDate(word(date.1, 1, sep = fixed(" ")), format = "%m/%d/%Y"),]
mn_effort_18aug2023[ is.na(date_clean), ]

mn_effort_18aug2023[ , hist(yday(date_clean)) ,]
mn_effort_18aug2023[ , hist(year(date_clean)) ,]

#check other fields
names(mn_effort_18aug2023)


#tidy sampling methods
mn_effort_18aug2023[ , .N , sampling_method ]
mn_effort_18aug2023[ , .N , .(sampling_method, sampling_method_abbrev)]

#keep the abbreviation/code column because that's the only thing in the CPUE file
mn_effort_18aug2023[ , .N , sampling_method_abbrev , ]
mn_cpue_21aug2023[ , .N , sampling_method_abbrev]

any(is.na(match(mn_effort_18aug2023[ , unique(sampling_method_abbrev),], mn_cpue_21aug2023[ , unique(sampling_method_abbrev) , ])))
#all abbreviations are covered (we could come back to that to add full gears names field to the cpues)

sort(names(mn_effort_18aug2023))

#year
mn_effort_18aug2023[ , unique(year) , ]
mn_effort_18aug2023[ is.na(year),]
 sum(mn_effort_18aug2023[ ,year != year(date_clean)])
#non-issue, delete year column
mn_effort_18aug2023[ , year := NULL] 

#effort units
mn_effort_18aug2023[ , .N , sampling_method ]


mn_effort_18aug2023[ , summary(total_effort_1) ,]

mn_effort_18aug2023[ total_effort_1 <0 , , ]

ggplot( mn_effort_18aug2023[!total_effort_1 < 0 ], aes(total_effort_1, group = sampling_method))+
  geom_density()+
  facet_wrap(~sampling_method, scales = "free")

# we can get units for these effort data from here (p45ish):
# https://files.dnr.state.mn.us/publications/fisheries/special_reports/180.pdf




```



# CPUE 2(3) ways
We have CPUE directly form the DNR, we can generate our own cpue using the individual fish data (both including and excluding the fish marked for CPUE inclusion)
Update 15 Sep 2023: We recieved a new data rip from MN DNR in three pieces: effort, catch, and cpue. Why catch and CPUE you ask? Because the DNR tells me that there are historical surveys (pre ~1985) that have CPUEs but no data for the indiv fish caught in those surveys. 

```{r}

  #cpue data
  mn_cpue_21aug2023[  , .N , .(lake_id, date, sampling_method_abbrev, survey_type, species) ]
  sum(duplicated(mn_cpue_21aug2023))
  #not really sure why there would be duplicated cpues in there... 
  mn_cpue_21aug2023[duplicated(mn_cpue_21aug2023) , .N, .(lake_name, lake_id, date) ]
  #if these cpues are calc'd per net or instance, that could cause it. how many of each gear in each survey?
  mn_cpue_21aug2023[ , .N, .(lake_name, lake_id, date, species, sampling_method_abbrev) ][, summary(N)]
  mn_cpue_21aug2023[ ,mean(total_effort), .(sampling_method_abbrev) ]
  mn_cpue_21aug2023[ , .N, .(lake_name, lake_id, date, species, sampling_method_abbrev) ][N>1, ]

  #not likely a problem. I think sometimes multiple rows are reported for a given gear on a survey, when the catch is == between two of them you get an aparrent "duplicate". This would be mitigated by a sub_effort_ident coming from the db. 
  
  #we'll be circling back to this dataset as a way to get the historical un-lengthed fish data into our fish-obs-as-rows format
  
  
  #fix up dates
  mn_cpue_21aug2023[ , date_clean :=  as.IDate(date),]
  mn_cpue_21aug2023[ is.na(date_clean), ]

  mn_cpue_21aug2023[ , hist(yday(date_clean)) ,]
  mn_cpue_21aug2023[ , .N ,.(lake_name,lake_id,year(date_clean))][ , hist(year) ,]
  
  #compared to the effort file, it's obvious there is overlap in these and that the CPUE stuff has more old data
  mn_effort_18aug2023[ ,.N ,.(lake_name,lake_id,year(date_clean))][ , hist(year) ,]
  
  
  #check overlap betweek effort and CPUE:
  mn_cpue_21aug2023[            , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ]
  mn_effort_18aug2023[          , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ]

   mn_cpue_21aug2023[            , .("cpueN" = .N) , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ][
     mn_effort_18aug2023[          , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ], 
     on = .(lake_id, date_clean, sampling_method_abbrev, survey_type) , effortN := "N" 
   ][ , .N , .("missingCPUE" = is.na(cpueN), "missing_effort" = is.na(effortN))] #
   

   
  mn_cpue_21aug2023[            , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ]
  mn_effort_18aug2023[          , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ]

   mn_cpue_21aug2023[            , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ][
     mn_effort_18aug2023[          , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ], 
     on = .(lake_id, date_clean, sampling_method_abbrev, survey_type) , 
   ]
  
  # Awesome-- the effort data are entirely contained in the cpue file. So here's a plan: 
   # 1. we use the fish obs and effort to set up our obs level file
   #  2a. Identify CPUE rows unmatched in the obs level surveys (for which we have nothing in effort or indiv fish). 
   #  2b. expand those rows into obs level format (but no wieghts or lengths)
   #  2c. bring them back to that main obs level file
  
```


# Prep & Scope Indiv Fish Data

```{r}

#inspect data
colnames(mn_indiv_fish_23nov2023)
sort(colnames(mn_indiv_fish_23nov2023))

setcolorder(mn_indiv_fish_23nov2023, c("lake_id", "date.2", "date.1", "sampling_method_abbrev", "survey_type")) 

mn_indiv_fish_23nov2023[ , .N , .(sampling_method_abbrev, species)  ]
mn_indiv_fish_23nov2023[ species == "WAE", .N , .(sampling_method_abbrev)  ] 
mn_indiv_fish_23nov2023[ species == "WAE", .N , .(sampling_method_abbrev)  ][ , sum(N) , ]

#to-do:
# make these clean: "lake_id", "date_clean", "sampling_method", "survey_type.1"

#dates (from data explainer we know that date.2 is survey date, we prob want to join on that one to connect to the effort data)
mn_indiv_fish_23nov2023[ , .(date.2, date.1), ]
mn_indiv_fish_23nov2023[ , .N , .(date1=is.na(date.1), date2=is.na(date.2)) ]

#change dates to Idate:
mn_indiv_fish_23nov2023[ , date_clean := as.IDate(date.2, format = "%m/%d/%Y") ,]

mn_indiv_fish_23nov2023[ , summary(date_clean) , ]
mn_indiv_fish_23nov2023[is.na(date_clean) , .N ]
#no missingness!


#lake_id
mn_indiv_fish_23nov2023[ , summary(lake_id) ,]
mn_indiv_fish_23nov2023[ , str(lake_id), ]
mn_effort_18aug2023[ , str(lake_id) ,]
#no issues here


#tidy sampling methods
mn_indiv_fish_23nov2023[ , .N , .(sampling_method_abbrev)]
mn_effort_18aug2023[ , .N , .(sampling_method, sampling_method_abbrev)]


any(is.na(match(mn_effort_18aug2023[ , unique(sampling_method_abbrev),], mn_indiv_fish_23nov2023[ , unique(sampling_method_abbrev) , ])))
#all abbreviations are covered (we could come back to that to add full gears to the indiv fish, but that'll hapen in the merge, so skipped here. )


#survey.type
mn_indiv_fish_23nov2023[ , .N , survey_type ]
mn_effort_18aug2023[ , .N , survey_type]

mn_indiv_fish_23nov2023[ , .N , survey_type ][ ,survey_type, ]


# generate a type table (these codes can be found in MN_Data folder)
# Assuming you have the data in a vector or a data frame column named 'codes'
codes <- c("IS", "RS", "PA", "SA", "CR", "WK", "DO", "GM", "CP", "LL", "SS", "NR", "OT", "RE", "XM", "XR", "SD", "TS")
full_names <- c("Initial Survey", "Re-Survey", "Population Assessment", "Special Assessment", "Creel Survey", "Winter Kill Assessment", 
                "Dissolved Oxygen Check", "Game Survey", "Collectors Permit", "Large Lake Survey", "Subsurvey", "Natural Reproduction Check", 
                "Investigational Survey", "Research Survey", "External Management Survey", "External Research Survey", "Standard Survey", "Targeted Survey")

# Create a data.table
survey_type_key <- data.table(code = codes, fullname = full_names)

# Print the resulting data.table
print(survey_type_key)


#execute
any(is.na(match(mn_indiv_fish_23nov2023[ , survey_type], survey_type_key[,code]))) #add codes are in key
# survey_type_key[match(mn_indiv_fish_23nov2023[ , survey_type], survey_type_key[,code]), fullname]

mn_indiv_fish_23nov2023[ , survey_type := survey_type_key[match(mn_indiv_fish_23nov2023[ , survey_type], survey_type_key[,code]), fullname]   ,]
rm(survey_type_key)

#uncount indiv_fish
mn_indiv_fish_23nov2023[, summary(total_count) , ]
mn_indiv_fish_23nov2023[total_count == 0 , .N , ]

#expected result size:
mn_indiv_fish_23nov2023[ , sum(total_count) , ] + mn_indiv_fish_23nov2023[total_count == 0 , .N , ]


#execute dataset expansion/uncount
mn_indiv_fish_23nov2023 <- 
rbind(
  mn_indiv_fish_23nov2023[total_count == 0 , , ], 
  uncount(mn_indiv_fish_23nov2023, weights = total_count, .remove = F)
)



#summarize ages
mn_indiv_fish_23nov2023[ , .N , age ]
mn_indiv_fish_23nov2023[ , .N , .(age=!is.na(age))]


```



# Merge effort and indiv fish

```{r}
#merge the effort and indiv fish data


#scope the merge:
#99% of the wb in the effort data are represneted in indiv fish data
sum(mn_indiv_fish_23nov2023[ , unique(lake_id) , ] %in% mn_effort_18aug2023[ , unique(lake_id)])/mn_effort_18aug2023[, length(unique(lake_id)) ,] 

#100% of the wb in the indiv fish data are represneted in  effort data
sum(mn_indiv_fish_23nov2023[ , unique(lake_id) , ] %in% mn_effort_18aug2023[ , unique(lake_id)])/mn_indiv_fish_23nov2023[, length(unique(lake_id)) ,] 

#merge the effort and indiv fish data

intersect(names(mn_effort_18aug2023), names(mn_indiv_fish_23nov2023))

#MEMORY HOG PINCH POINT
#we know that dates are a problem, can we schmooze that join? 
#we leave many column names out of this merge key to avoid disconnecting things where one dataset has empty info
flatfish <- merge(mn_effort_18aug2023,mn_indiv_fish_23nov2023, by = c("lake_id", "date_clean" , "sampling_method_abbrev", "survey_type"), suffixes = c("_effort", "_indivfish"), all = T)

rm(mn_indiv_fish_23nov2023,mn_effort_18aug2023)

flatfish[ , .N , sampling_method]
flatfish[ , .N, species]


#check on the annual #s of aged, lengthed, both, and neither numbers
a <- setnames(dcast(flatfish[ (species == "WAE" & sampling_method %in% c("Standard gill net sets")), .N, .(year = year(date_clean), age = !is.na(age), length = !is.na(length))][order(year, -N)],
      formula = year ~ age + length, fill = 0 ), old = c("FALSE_FALSE", "FALSE_TRUE", "TRUE_TRUE"), new = c("neither", "age_only", "length_only"))


names(flatfish)

#how many unique surveys exist for each category of has effort and has indiv fish data?
flatfish[ , length(unique(paste(lake_id, date_clean , sampling_method, survey_type))) , .(effort = !is.na(state_effort), indiv_fish_dat = !is.na(state_indivfish)) ]
  
#sum of all
  flatfish[ , length(unique(paste(lake_id, date_clean , sampling_method, survey_type))) , .(effort = !is.na(state_effort), indiv_fish_dat = !is.na(state_indivfish)) ][ , sum(V1) , ]

  
  
#now roll the catch CPUE data back to this bigger file:
  
##Context foir this next operation:
#   3. Historical WAE survey duplications show same gear/lake/date cathing many (from CPUE) and zero (from indivfish)
# - Consider dropping the effort table info where we have a HISTORICAL cpue record (or at least scope this strategy)


     
  #We've got a bad survey type thingy going on here where cpue is historical:
   mn_cpue_21aug2023[ , .N , survey_type ]
   flatfish[, .N , survey_type]
   
   # consider dropping records from the effort table where we have a cpue in a historical?
   #send this off to Corey Geving to review 
   
  flatfish[mn_cpue_21aug2023[survey_type == "HISTORICAL", , ], on = .(lake_id, date_clean, sampling_method_abbrev) , nomatch = NULL ][ , .(neffcatch = .N, n_cpue = sum(i.total_count), nlen = sum(!is.na(length))) , .(lake_id, date_clean, sampling_method_abbrev, survey_type, i.survey_type) ][order(lake_id,date_clean)] 
  
  
  #for these records we want to push the flatfish record out completely. 
  badflatfish <- flatfish[mn_cpue_21aug2023[survey_type == "HISTORICAL", , ], on = .(lake_id, date_clean, sampling_method_abbrev) , nomatch = NULL ][ , .(neffcatch = .N, n_cpue = sum(i.total_count), nlen = sum(!is.na(length))) , .(lake_id, date_clean, sampling_method_abbrev, survey_type, i.survey_type) ][order(lake_id,date_clean)][nlen %in% c(0), ]
  
  
  flatfish <- flatfish[!badflatfish, on = .(lake_id, date_clean, sampling_method_abbrev,survey_type) ]
  
  

  #subset of MN_cpue where lake/date/method are not matched:
   glimpse(mn_cpue_21aug2023[ 
     !flatfish[          , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ], 
     on = .(lake_id, date_clean, sampling_method_abbrev, survey_type) , 
   ])
  
  #trim to only the not already covered data:
  mn_cpue_21aug2023 <- mn_cpue_21aug2023[ 
     !flatfish[          , .N , .(lake_id, date_clean, sampling_method_abbrev, survey_type) ], 
     on = .(lake_id, date_clean, sampling_method_abbrev, survey_type) , 
   ]
  
  mn_cpue_21aug2023[ , summary(total_count) , ]
  
  #execute dataset expansion/uncount
mn_cpue_21aug2023 <- 
rbind(
  mn_cpue_21aug2023[total_count == 0 , , ], 
  uncount(mn_cpue_21aug2023, weights = total_count, .remove = F)
)

names(flatfish)


  #MEMORY HOG STEP
  #now bring that together with the flatfish data:
  flatfish <- rbindlist(list(flatfish, mn_cpue_21aug2023 ),
                               fill = TRUE,
                               use.names = TRUE)
  
  rm(mn_cpue_21aug2023)
  
  #for each of those with both effort and fish data, summarize catch by species (bring effort along too!)   
flatfish[ !is.na(state_effort)&!is.na(state_indivfish) , .N , .(lake_id, date_clean , sampling_method, survey_type, species, total_effort_1) ]


  
```


# Save an rds to work from 
```{r}





# saveRDS(flatfish, file = "Data_and_Scripts\\Data\\output\\mn_flat_effort_indivfish_merge.rds")


#this flatfish file is big AF and will slow down Mike's Hansen Lab Computer (32gb RAM)
# flatfish <- readRDS("Data_and_Scripts/Data/output/mn_flat_effort_indivfish_merge.rds")






```

# 

#Tidy up dataframe
```{r}
#we need to
# 1. revises the data in a few columns: sampling method, nothing caught, species names, state, units, target species, effort,  
# 2. export notes for the workshop. (delete, flag, clarify, keep for workshop) then dump those columns
# 3. match to schema (https://docs.google.com/spreadsheets/d/1zfevASMxRMxMYNWm3Hq1yR2Qk0zcJV_JnO0LBeODaPQ/edit#gid=0)

mn_dat <- flatfish
rm(flatfish)
names(mn_dat)

# dump some known trash

mn_dat[, c("targeted_or_standard_effort", "targeted_or_standard_indivfish", "targeted_or_standard",
           "new_file_name_effort", "new_file_name_indivfish", "new_file_name",
           "source_contact_effort", "source_agency", "source_agency_effort", "source_contact_indivfish", "source_agency_indivfish", "source_contact",
           "file_status_effort", "file_type_effort", "file_status_indivfish", "file_type_indivfish", "file_status", "file_type",
           "jan2023_inventoried_effort", "jan2023_inventoried_indivfish", "jan2023_inventoried",
           "data_type_effort", "data_type_indivfish", "data_type",
           "date_recieved_effort", "date_recieved_indivfish", "date_recieved", 
           "unique_row_key_effort", "unique_row_key_indivfish", "unique_row_key",
           "total_count") := NULL, ]


#gear full names need filling out
    mn_dat[ , .N , .(sampling_method_abbrev, sampling_method)]
    
    #borrow codes as key from other rows
    gear_table_mn <- mn_dat[!is.na(sampling_method), .N , .(sampling_method_abbrev,sampling_method) ]
    
    
    #apply these to all rows
    #drop old col
    mn_dat[ , sampling_method := NULL ,]
    #rejoin to complete gear table
    mn_dat[gear_table_mn,
      on = .(sampling_method_abbrev), sampling_method := sampling_method
          ]
    #checkwork
    mn_dat[ , .N , .(sampling_method_abbrev, sampling_method)]
    
 
#add nothing_caught
    mn_dat[is.na(species), nothing_caught := T , ] #The only species == NA are places where lake/date/gear/surveytype found no species
     
    
#species names are mixed codes and names
    #what cols are have species in name?
    mn_dat %>%
      select(contains("species"))
    #show problem
    mn_dat[ , .N , species ]
    
    # Review "codes" as defined by 3 letter species names
    print(mn_dat[nchar(species) == 3, .N , species ],
          nrow(mn_dat[nchar(species) == 3, .N , species ]))
    
    # choose only species.1 length of 3, assign these to a species_code
    mn_dat[nchar(species) == 3, `:=` (species_abbrev = species, species = NA) , ]
    
    
    #generate a species code table (will also use later to fix target species cols)    
      species_codes_mn <-  mn_dat[!is.na(species_abbrev), .(species_abbrev = unique(species_abbrev)) ,  ] 
    
    #adds names to that table (uses key provided by Jon Hansen, MNDNR on 10 Oct 2023: https://docs.google.com/spreadsheets/d/1ZakE4S2zfSdYNEWHfikFqILNnD1gYpNf?rtpof=true&usp=drive_fs )    
        #This chunk cleans codes and names within the species column, references? for codes?
      species_codes_mn[ , species := 
                          case_when(# first fish codes are converted,
                            species_abbrev == "LMB" ~ "largemouth_bass",
                            species_abbrev == "SMB" ~ "smallmouth_bass",
                            species_abbrev == "WAE" ~ "walleye", 
                            species_abbrev == "WTS" ~ "white_sucker",
                            species_abbrev == "BLC" ~ "black_crappie",
                            species_abbrev == "YEP" ~ "yellow_perch",
                            species_abbrev == "BLG" ~ "bluegill",
                            species_abbrev == "NOP" ~ "northern_pike",
                            species_abbrev == "PMK" ~ "pumpkinseed", 
                            species_abbrev == "RKB" ~ "rock_bass",
                            species_abbrev == "BKF" ~ "banded_killifish",
                            species_abbrev == "IOD" ~ "iowa_darter",
                            species_abbrev == "BCS" ~ "blackchin_shiner",
                            species_abbrev == "BLB" ~ "black_bullhead",
                            species_abbrev == "JND" ~ "johnny_darter",
                            species_abbrev == "GOS" ~ "golden_shiner",
                            species_abbrev == "YEB" ~ "yellow_bullhead",
                            species_abbrev == "BRB" ~ "brown_bullhead",
                            species_abbrev == "CNM" ~ "central_mudminnow",
                            species_abbrev == "NRD" ~ "northern_redbelly_dace",
                            species_abbrev == "CSH" ~ "chinook_salmon",
                            species_abbrev == "MTS" ~ "mottled_sculpin",
                            species_abbrev == "TPM" ~ "tadpole_madtom",
                            species_abbrev == "SHR" ~ "shorthead_redhorse",
                            species_abbrev == "HSF" ~ "hybrid_sunfish",
                            species_abbrev == "BOF" ~ "bowfin",
                            species_abbrev == "WDS" ~ "weed_shiner",
                            species_abbrev == "BNM" ~ "bluntnose_minnow",
                            species_abbrev == "BND" ~ "blacknose_dace",
                            species_abbrev == "OTM" ~ "minnows",
                            species_abbrev == "FHM" ~ "fathead_minnow",
                            species_abbrev == "FND" ~ "finescale_dace",
                            species_abbrev == "SDM" ~ "slender_madtom",
                            species_abbrev == "SPO" ~ "spottail_shiner",
                            species_abbrev == "BNS" ~ "blacknose_shiner",
                            species_abbrev == "BKT" ~ "brook_trout",
                            species_abbrev == "SPT" ~ "splake",
                            species_abbrev == "RBT" ~ "rainbow_trout",
                            species_abbrev == "BNT" ~ "brown_trout",
                            species_abbrev == "BUB" ~ "burbot",
                            species_abbrev == "BIB" ~ "bigmouth_buffalo",
                            species_abbrev == "BLH" ~ "bullheads",
                            species_abbrev == "TLC" ~ "cisco",
                            species_abbrev == "CCF" ~ "channel_catfish",
                            species_abbrev == "BSD" ~ "blackside_darter",
                            species_abbrev == "BKS" ~ "brook_silverside",
                            species_abbrev == "LED" ~ "least_darter",
                            species_abbrev == "LGP" ~ "logperch",
                            species_abbrev == "SLR" ~ "silver_redhorse",
                            species_abbrev == "HHC" ~ "hornyhead_chub",
                            species_abbrev == "MUE" ~ "muskellunge",
                            species_abbrev == "TRP" ~ "trout_perch",
                            species_abbrev == "RHS" ~ "redhorse",
                            species_abbrev == "CAP" ~ "common_carp",
                            species_abbrev == "MMS" ~ "mimic_shiner",
                            species_abbrev == "EMS" ~ "emerald_shiner",
                            species_abbrev == "SUN" ~ "sunfish",
                            species_abbrev == "CRC" ~ "creek_chub",
                            species_abbrev == "GSF" ~ "green_sunfish",
                            species_abbrev == "SFS" ~ "spotfin_shiner",
                            species_abbrev == "SHI" ~ "shiners",
                            species_abbrev == "BST" ~ "brook_stickleback",
                            species_abbrev == "CSR" ~ "central_stoneroller",
                            species_abbrev == "SDS" ~ "sand_shiner",
                            species_abbrev == "GRR" ~ "greater_redhorse",
                            species_abbrev == "PGS" ~ "pugnose_shiner",
                            species_abbrev == "SMS" ~ "slimy_sculpin",
                            species_abbrev == "LND" ~ "longnose_dace",
                            species_abbrev == "FRD" ~ "freshwater_drum",
                            species_abbrev == "WHC" ~ "white_crappie",
                            species_abbrev == "DAR" ~ "darters",
                            species_abbrev == "SAR" ~ "sauger",
                            species_abbrev == "FCF" ~ "flathead_catfish",
                            species_abbrev == "BMS" ~ "bigmouth_shiner",
                            species_abbrev == "LKS" ~ "lake_sturgeon",
                            species_abbrev == "LKW" ~ "lake_whitefish",
                            species_abbrev == "BRM" ~ "brassy_minnow",
                            species_abbrev == "SLM" ~ "mississippi_silvery_minnow",
                            species_abbrev == "GLR" ~ "golden_redhorse",
                            species_abbrev == "OTS" ~ "suckers",
                            species_abbrev == "NST" ~ "ninespine_stickleback",
                            species_abbrev == "GOE" ~ "goldeye",
                            species_abbrev == "QBS" ~ "quillback",
                            species_abbrev == "RVS" ~ "river_shiner",
                            species_abbrev == "LES" ~ "longear_sunfish",
                            species_abbrev == "CHL" ~ "chestnut_lamprey",
                            species_abbrev == "RRH" ~ "river_redhorse",
                            species_abbrev == "WHB" ~ "white_bass",
                            species_abbrev == "OSS" ~ "orangespotted_sunfish",
                            species_abbrev == "STC" ~ "stonecat",
                            species_abbrev == "SNG" ~ "shortnose_gar",
                            species_abbrev == "RFS" ~ "rosyface_shiner",
                            species_abbrev == "CMS" ~ "carmine_shiner",
                            species_abbrev == "SAB" ~ "smallmouth_buffalo",
                            species_abbrev == "GIS" ~ "gizzard_shad",
                            species_abbrev == "LNG" ~ "longnose_gar",
                            species_abbrev == "RCS" ~ "river_carpsucker",
                            species_abbrev == "SLS" ~ "shovelnose_sturgeon",
                            species_abbrev == "LAT" ~ "lake_trout",
                            species_abbrev == "TME" ~ "tiger_muskellunge",
                            species_abbrev == "PRD" ~ "pearl_dace",
                            species_abbrev == "PLS" ~ "pallid_shiner",
                            species_abbrev == "RBS" ~ "rainbow_smelt",
                            species_abbrev == "RBD" ~ "rainbow_darter",
                            species_abbrev == "LNS" ~ "longnose_sucker",
                            species_abbrev == "SJC" ~ "shortjaw_cisco",
                            species_abbrev == "DWS" ~ "deepwater_sculpin",
                            species_abbrev == "SHS" ~ "spoonhead_sculpin",
                            species_abbrev == "BDD" ~ "banded_darter",
                            species_abbrev == "MOE" ~ "mooneye",
                            species_abbrev == "BLS" ~ "blue_sucker",
                            species_abbrev == "SLC" ~ "silver_chub",
                            species_abbrev == "HFS" ~ "highfin_carpsucker",
                            species_abbrev == "MCP" ~ "mirror_carp",
                            species_abbrev == "WAS" ~ "walleye/sauger",
                            species_abbrev == "AME" ~ "american_eel",
                            species_abbrev == "GOF" ~ "goldfish",
                            species_abbrev == "SPS" ~ "spotted_sucker",
                            species_abbrev == "PAH" ~ "paddlefish",
                            species_abbrev == "RVD" ~ "river_darter",
                            species_abbrev == "NHS" ~ "northern_hog_sucker",
                            species_abbrev == "BHM" ~ "bullhead_minnow",
                            species_abbrev == "WSD" ~ "western_sand_darter",
                            species_abbrev == "MDD" ~ "mud_darter",
                            species_abbrev == "SIL" ~ "silver_lamprey",
                            species_abbrev == "SKJ" ~ "skipjack_herring",
                            species_abbrev == "PGM" ~ "pugnose_minnow",
                            species_abbrev == "BKB" ~ "black_buffalo",
                            species_abbrev == "FTD" ~ "fantail_darter",
                            species_abbrev == "YLB" ~ "yellow_bass",
                            species_abbrev == "PRP" ~ "pirate_perch",
                            species_abbrev == "LKC" ~ "lake_chub",
                            species_abbrev == "RIR" ~ "river_ruffe",
                            species_abbrev == "WHP" ~ "white_perch",
                            species_abbrev == "ALW" ~ "alewife",
                            species_abbrev == "SEL" ~ "sea_lamprey",
                            species_abbrev == "BHC" ~ "bighead_carp",
                            species_abbrev == "GLD" ~ "gilt_darter",
                            species_abbrev == "CRD" ~ "crystal_darter",
                            species_abbrev == "SMT" ~ "speckled_madtom",
                            species_abbrev == "RDS" ~ "red_shiner",
                            species_abbrev == "WAM" ~ "warmouth",
                            species_abbrev == "CIS" ~ "cisco",
                            species_abbrev == "CPS" ~ "carpsucker",
                            species_abbrev == "CRP" ~ "crappie",
                            species_abbrev == "HCR" ~ "hybrid_crappie",
                            species_abbrev == "SCU" ~ "sculpin",
                            species_abbrev == "SHD" ~ "slenderhead_darter",
                            species_abbrev == "SIP" ~ "northern_pike_silver_phase",
                            species_abbrev == "UK1" ~ "unknown_fish",
                            species_abbrev == "UK2" ~ "unknown_fish",
                            # below unknown codes specified as such
                            species_abbrev == "LXB" ~ "see_ambiguous_species_code",
                            TRUE ~ species_abbrev
                          )
      ]
      
      #some dulicated common names (two codes for one thing)
      species_codes_mn[duplicated(species_codes_mn$species), , ]
      
      setnames(species_codes_mn, "species" , "common.name" )
      
        #fill species names
      mn_dat[species_codes_mn,
             on = .(species_abbrev=species_abbrev),
             species.fix := common.name 
      ]
        #fill into species.1 col, drop fix column
        mn_dat[is.na(species), species := species.fix , ]
        mn_dat[ , species.fix := NULL ,]
       
        
        #clean up common names
        mn_dat[ , species := str_replace_all( str_replace_all( str_replace_all(tolower(species),
                                                                                 " ", "_") ,
                                                                 "\\)" , "") ,
                                                "\\(" , "")]
        
        mn_dat[ , species := 
                  case_when(
                    species == "tullibee_cisco" ~ "cisco",
                    species == "trout-perch" ~ "trout_perch",
                    species == "bowfin dogfish" ~ "bowfin",
                    # unknown species
                    species == "no_particular_species" ~ "no_particular_species",
                    species == "unknown_fish_one" ~ "unknown_fish",
                    species == "walleye/sauger" ~ "walleye_x_sauger",
                    TRUE ~ species
                  )
        ]
        
        #check work
        print(mn_dat[ , .N , species][order(species)], nrow(mn_dat[ , .N , species])) 
        
        #still 1876 NAs here (nothing caught surveyXgears)
        mn_dat[is.na(species) , .N , .(nothing_caught)  ]
        
        
        #drop species codes
        species_codes_mn
        mn_dat[, .N , .(species_abbrev,species) ]
        mn_dat[ , `:=` (species_abbrev = NULL)]

        
# fix state
       #what cols are have species in name?
    mn_dat[ , .N ,  .(state, state_effort, state_indivfish) ]
    
    #collapse all
    mn_dat[ , `:=` (state = "Minnesota", state_effort = NULL, state_indivfish = NULL) , ]
    
#fix county
    mn_dat[ , .N ,  .(county_effort, county_indivfish) ]
    mn_dat[is.na(county_effort), county_effort := county_indivfish ]
              mn_dat[ , c("county_indivfish") := NULL]
    

# fix unit names for length and age
    #formats the length unit for clarity
    mn_dat[ , .N , length_unit ]
      mn_dat[ !is.na(length) ,.N  , length_unit ]
    
    mn_dat[ , .N , weight_unit]
      mn_dat[ !is.na(weight) ,.N  , weight_unit ]
    
    mn_dat[!is.na(length_unit), length_unit := "mm" ,]
    mn_dat[!is.na(weight_unit), weight_unit := "g" ,]

# target species
    #targeted species - needs cleaning, has species codes (clean up with the species code table generated above)
    mn_dat[ , .N , target_species ]
    mn_dat[ , c("T1","T2", "T3", "T4", "T5")  :=   tstrsplit(target_species, split = ", "), ]
    
    mn_dat[species_codes_mn, on = .(T1=species_abbrev) , target_species_1 := common.name ]
    mn_dat[species_codes_mn, on = .(T2=species_abbrev) , target_species_2 := common.name ]
    mn_dat[species_codes_mn, on = .(T3=species_abbrev) , target_species_3 := common.name ]
    mn_dat[species_codes_mn, on = .(T4=species_abbrev) , target_species_4 := common.name ]
    mn_dat[species_codes_mn, on = .(T5=species_abbrev) , target_species_5 := common.name ]
    
    mn_dat[ !is.na(target_species), unique(paste(target_species_1,target_species_2, target_species_3, target_species_4,target_species_5))]
    
    mn_dat[ , target_species := str_remove_all(paste(target_species_1,target_species_2, target_species_3, target_species_4,target_species_5, sep = ", "),
                                               ", NA"),]
    
    mn_dat[ , c("T1","T2", "T3", "T4", "T5",
                "target_species_1","target_species_2", "target_species_3", "target_species_4", "target_species_5") := NULL]
    
# effort needs attention. Currently we have a negative effort and no units (nab code to add units from Holly based on gear type)
    #effort
    mn_dat %>% 
      select(contains("effort")) %>% 
      colnames()
    #total_effort_1.1
    
    gear_table_mn[order(sampling_method_abbrev)]
    
    mn_dat[ !is.na(total_effort_1), .(mean = mean(total_effort_1), min =min(total_effort_1), max = max(total_effort_1)) , ]
    #no effort units, we have a negative effort? 
    
    # we can get units for these effort data from here (p45ish):
    # https://files.dnr.state.mn.us/publications/fisheries/special_reports/180.pdf
    #manually added the units for AOW, TMF, and GFM -- assuming same as similar gear categories
    effort_table <- data.table( CODE = c(c("AIF", "TOU", "ATL", "STL", "EXT", "XXX", "MT", "SA", "ZO", "AOW"),#NONE
                                 c("TR" , "STR", "SEF", "EFB", "EW", "EF"), #HOUR 
                                 c("SSE", "SE", "S18", "S58"), #HAUL
                                 c("GN", "GDE", "GSH", "GSM", "GST", "GSU", "GNP", "FCI", "TML", "SGN", "GNA", "VGN", "TN", "LTN", "DTN", "TQU", "T38", "THA", "T34", "T1", "STN", "GFM", "TMF")),#SET  
                        effort_unit = c(rep("no_unit", 10), rep("hours", 6), rep("haul", 4), rep("set", 23)))
    
    effort_table <- data.table(
  Code = c("GN", "GDE", "GSH", "GSM", "GST", "GSU", "GNP", "FCI", "TML", "SGN", "GNA", "VGN", "TN", "LTN", "DTN", "TQU", "T38", "THA", "T34", "T1", "STN", "EF", "EW", "EFB", "SEF", "S58", "S18", "SE", "SSE", "AIF", "AOW", "TOU", "ATL", "STL", "TR", "STR", "EXT", "XXX", "MT", "SA", "ZO"),
  Method = c("Gill net Standard graduated-mesh gill net", "Gill net Deep GN net, in waters colder than 12 o C", "Gill net Shallow GN net, in waters warmer than 12 o C", "Gill net Small-mesh (0.375 and 0.5-in-bar) net", "Gill net Short-term sets, monofilament net", "Gill net Suspended set, any gill net type", "Gill net Large-mesh (1.5, 2.0, 2.5-in bar) net", "Gill net Fish Community Index nets (Ontario)", "Gill net Trammel net", "Gill net Other (special) gill net", "Gill net Standard North American gill net", "Gill net Vertical gill net", "Trap net Standard 0.75-in-mesh double-frame net", "Trap net Large-frame (5x6 ft) net", "Trap net Pair of TN nets, set in double-pot configuration", "Trap net 0.25-in-mesh net", "Trap net 0.375-in-mesh net", "Trap net 0.5-in-mesh net", "Trap net 0.75-in-mesh single-frame net", "Trap net 1.0-in-mesh net", "Trap net Other (special) trap net", "Electrofishing Standard Boat electrofishing", "Electrofishing Fall electrofishing targeting Walleye", "Electrofishing Backpack electrofishing", "Electrofishing Other (special) electrofishing", "Seine 50-ft bag seine, 0.125-in mesh", "Seine 15-ft seine, 0.125-in mesh", "Seine 50-ft bag seine, 0.25-in mesh", "Seine Other (special) seining", "Angling Ice fishing", "Angling Open-water angling", "Angling Tournament angling", "Trot line Normal trot-line configuration", "Trot line Other (special) trot line", "Trawl Large lake trawl", "Trawl Other (special) trawl", "Miscellaneous Fish collected from or by an external source", "Miscellaneous Fish taken by miscellaneous means", "Miscellaneous 0.25-in-mesh minnow trap", "Miscellaneous Fish spawning trap", "Zooplankton Zooplankton sampling gear"),
  effort_unit = c("net-night", "net-night", "net-night", "net-night", "Set", "net-night", "net-night", "net-night", "net-night", "Set", "net-night", "net-night", "net-night", "net-night", "net-night", "net-night", "net-night", "net-night", "net-night", "net-night","Set", "Hours", "Hours", "Hours", "Hours", "Haul", "Haul", "Haul", "Haul", "None", "None", "None", "None", "None", "Hour", "Hour", "None", "None", "None", "None", "None")
)
    
    
    #add effort units to gear tbale       
    gear_table_mn[effort_table, on = .(sampling_method_abbrev=Code), `:=` (total_effort_unit = effort_unit, sampling_method_desc = Method)]
    
    #and push those over to the main df
    mn_dat[gear_table_mn, on = .(sampling_method_abbrev), `:=` (total_effort_unit = total_effort_unit, sampling_method_desc = sampling_method_desc)]
    
    #cleanup and checkwork
    rm(effort_table)
    mn_dat[ , .N , .(sampling_method,sampling_method_desc,  total_effort_unit)]
    
    mn_dat[ total_effort_1 < 0 ] #weird, but not diagnosable/fixable IMO.
    mn_dat[ total_effort_1 < 0, flag := "effort value error" ]
    
    
#survey_id 
    mn_dat %>%
      select(contains("survey_")) %>% 
      colnames()
    
    mn_dat[ ,  .N, .(is.na(survey_id), is.na(survey_id_effort))]
    
    #something looks wonky in these survey Ids but the MNDNR says they're not useful anyways... see Minnnesota_README (https://docs.google.com/document/d/1sXag9RDvbKN0pUB6uRlADz36-kFNqRPwHVGlkJgyWTM/edit)
    
    mn_dat[ , `:=` (survey_id = NULL, survey_id_effort = NULL, survey_id_indivfish = NULL) , ]
    
    
#lake_name
              mn_dat[, .N, .(catchisNA = is.na(lake_name),
                                                                effortisNA = is.na(lake_name_effort),
                                                                fishisNA = is.na(lake_name_indivfish))
                 ]
            mn_dat %>% 
            mutate(same_survID_eff_fish = ifelse(lake_name_effort == lake_name_indivfish, "Same", "Different")) %>% 
            mutate(same_survID_eff_catch = ifelse(lake_name_effort == lake_name, "Same", "Different")) %>% 
            mutate(same_survID_catch_fish = ifelse(lake_name == lake_name_indivfish, "Same", "Different")) %>% 
            group_by(same_survID_eff_fish,same_survID_eff_catch,same_survID_catch_fish) %>% 
            count()
          
            mn_dat[is.na(lake_name), lake_name := ifelse(is.na(lake_name_effort), lake_name_indivfish, lake_name_effort)]
              mn_dat[ , c("lake_name_effort","lake_name_indivfish") := NULL]
              
#date
              sort(names(mn_dat))
              
                  mn_dat %>% 
      select(contains("date")) %>% 
      colnames()
              
              mn_dat[ , .N , is.na(date_clean)]
              
              #dump all extra dates:
              #mn_dat[ , c("date.1_effort", "date.2_effort", "end_date", "date.2_indivfish", "date.1_indivfish", "date") := NULL, ]
              
              
# add an effort_ident column "lake_id", "date_clean" , "sampling_method_abbrev", "survey_type.1"effort_ident := .GRP
    mn_dat[ , .N ,.(lake_id, date_clean, survey_type, sampling_method  #survey 
                                                        ) ]  
        #verify extra fields align with this level
        mn_dat[ , .N ,.( lake_id, date_clean, survey_type, #survey 
                        sampling_method_abbrev, total_effort_1, total_effort_unit, nothing_caught 
                                                        ) ] 
        #adds in our effort_ident field
        mn_dat[ , total_effort_ident := .GRP ,.( lake_id, date_clean, survey_type, #survey 
                        sampling_method_abbrev, total_effort_1, total_effort_unit, nothing_caught 
                                                        ) ] 
    
    
#use mwlaxeref to fetch NHDIDs
  mwlaxeref::mn_to_nhdhr(mn_dat, from_colname = "lake_id")[,nhdhr.id]
  
  mn_dat[ , nhdhr.id := mwlaxeref::mn_to_nhdhr(mn_dat, from_colname = "lake_id")[,nhdhr.id] , ]
    

  #remaining unmatched lakes:
  mn_dat[is.na(nhdhr.id), .N , lake_id ]
  
#CPUE Y/N column
  
  mn_dat[ , .N , notes.1 ]
  mn_dat[ notes.1 == "CPUE:N" , flag := ifelse(is.na(flag),
                                                                          "Do not use in CPUE calcs" ,
                                                                          paste(flag, "Do not use in CPUE calcs", sep = ";" ))]
  mn_dat[  , notes.1 := NULL , ]
  
#representative sampling column
  
  mn_dat[ , .N , notes ]
  mn_dat[ notes %in% c("REPRESENTATIVE_SAMPLING:N", "REPRESENTATIVE_SAMPLING:N, Y", "REPRESENTATIVE_SAMPLING:Y, N") , flag := ifelse(is.na(flag),
                                                                          "Not representative sampling" ,
                                                                          paste(flag, "Not representative sampling", sep = ";" ))]
  mn_dat[  , notes := NULL , ]  
  
#other notes  
  mn_dat[ , .N , notes.2] #send to workshop
  # workship results
  note_revisions <- fread("Data_and_Scripts\\Data\\input\\MN_comments_notes_reviewed.csv")
  
  note_revisions[ , .N , flag]
  
  note_revisions <- note_revisions[flag != "", .(flag,notes.2) ]
  
  setnames(note_revisions, "flag", "note_flag")
  
  mn_dat[note_revisions, on = .(notes.2), note_flag := note_flag]
    mn_dat[  , .N , note_flag]
  
  mn_dat[ !is.na(note_flag) , flag := ifelse(is.na(flag),
                                                                          note_flag ,
                                                                          paste(flag, note_flag, sep = ";" ))]
  mn_dat[str_detect() , .(n = .N, n_surv = length(unique(total_effort_ident))) , flag]
  
  mn_dat[  , notes.2 := NULL , ]  
    
    
    
    
  
  mn_dat[ , .N , garbage_bin_notes.1_indivfish] #junk
  mn_dat[ , .N , garbage_bin_notes.1_effort]#junk
  mn_dat[ , .N , garbage_bin_notes.2_effort] #junk
  mn_dat[ , .N , garbage_bin_notes.2_indivfish] #junk
  mn_dat[ , .N , garbage_bin_notes.3] # junk

  mn_dat[ , `:=` (garbage_bin_notes.1_indivfish = NULL, garbage_bin_notes.1_effort = NULL, garbage_bin_notes.2_effort = NULL, garbage_bin_notes.3 = NULL)]

  
      
#gear notes  
  mn_dat[ , gear_data_notes := paste(gear_data_notes,
                                     gear_data_notes.1,
                                     gear_data_notes.2,
                                     gear_data_notes.3,
                                     gear_data_notes.4,
                                     gear_data_notes.5, sep = "_") ,]
  
  mn_dat[ , .N, gear_data_notes]
  mn_dat[ , .N, gear_data_notes.1]
  mn_dat[ , .N, gear_data_notes.2]
  mn_dat[ , .N, gear_data_notes.3]
  mn_dat[ , .N, gear_data_notes.4]
  mn_dat[ , .N, gear_data_notes.5] #junk
   # mn_dat[!is.na(gear_data_notes.5) , .N , .(gear_data_notes.5, total_effort, total_effort_unit) ]
  
    mn_dat[ , gear_data_notes.1 := NULL , ]  
    mn_dat[ , gear_data_notes.2 := NULL , ]
    mn_dat[ , gear_data_notes.3 := NULL , ]
    mn_dat[ , gear_data_notes.4 := NULL , ]
    mn_dat[ , gear_data_notes.5 := NULL , ]
  
#location notes  
  mn_dat[!(location_notes %in% c("LOC_DESC:","LOC_DESC:null")|is.na(location_notes)) , .N , location_notes ]  #keep
  
#lake type
  mn_dat[ , .N , lake_type ] #minimal info, but keep for consistency to other states
  
#aging str
  mn_dat[ , .N , .(aging_structure.1, aging_structure.2) ]
  mn_dat[ aging_structure.1 == "" , aging_structure.1 := NA , ]
  mn_dat[aging_structure.2 == "" , aging_structure.2 := NA , ]
  

## Now grab exportable cols for the workshop
  names(mn_dat)
  
  
# #what cols go out to the team? (We'll carry these forward & round up at the end)
#   # gear stuff
#         dat <- mn_dat[ , .("records" = .N, "surveys" = length(unique(total_effort_ident))) , by= .(gear_data_notes, gear_data_notes.1, gear_data_notes.2, gear_data_notes.3, gear_data_notes.4,sampling_method, sampling_method_desc)]
#         
#         # Function to extract the first word from a string
#         extract_first_word <- function(x) {
#           non_na_values <- na.omit(x)
#           if (length(non_na_values) > 0) {
#             first_word <- strsplit(as.character(non_na_values[1]), " ")[[1]][1]
#             return(first_word)
#           }
#           return(NULL)
#         }
#         
#         # Loop through each column and update column name
#         for (col in names(dat)[1:3]) {
#           first_word <- extract_first_word(dat[[col]])
#           if (!is.null(first_word)) {
#             setnames(dat, col, first_word)
#           }
#         }
# 
#       # Function to strip the first word from a string
#       strip_first_word <- function(x) {
#         if (!is.na(x)) {
#           stripped_string <- sub("^[^:]+:", "", as.character(x))
#           return(stripped_string)
#         }
#         return(x)
#       }
#       
#       # Loop through each column and update values
#       for (col in names(dat)[1:3]) {
#         dat[, (col) := lapply(.SD[[col]], strip_first_word)]
#       }
#       
#       #fix column names
#       names(dat) <- word(names(dat), 1, sep = fixed(":"))
#       
#       # Print the updated data.table#write to file
#       
#       # fwrite(dat, file = "MN_gear_notes.csv")
#   
# # other generic notes
#         dat <- mn_dat[ , .("records" = .N, "surveys" = length(unique(total_effort_ident))) , by= .(garbage_bin_notes.2_indivfish, location_notes, notes, notes.2)]
#         
#         # Function to extract the first word from a string
#         extract_first_word <- function(x) {
#           non_na_values <- na.omit(x)
#           if (length(non_na_values) > 0) {
#             first_word <- strsplit(as.character(non_na_values[1]), " ")[[1]][1]
#             return(first_word)
#           }
#           return(NULL)
#         }
#         
#         # Loop through each column and update column name
#         for (col in names(dat)[1:3]) {
#           first_word <- extract_first_word(dat[[col]])
#           if (!is.null(first_word)) {
#             setnames(dat, col, first_word)
#           }
#         }
# 
#       # Function to strip the first word from a string
#       strip_first_word <- function(x) {
#         if (!is.na(x)) {
#           stripped_string <- sub("^[^:]+:", "", as.character(x))
#           return(stripped_string)
#         }
#         return(x)
#       }
#       
#       # Loop through each column and update values
#       for (col in names(dat)[1:3]) {
#         dat[, (col) := lapply(.SD[[col]], strip_first_word)]
#       }
#       
#       #fix column names
#       names(dat) <- word(names(dat), 1, sep = fixed(":"))
#       
#       # Print the updated data.table#write to file
#       
#       # fwrite(dat, file = "MN_comments_notes.csv")
#   
#   rm(col, first_word, dat)
#   
#   
#   
#   
  

# adds columns needed for state filtering
  #adding lake area to the data
area <- read_csv("Data_and_Scripts/Data/input/mn_lake_list.csv") %>%
  select(DOW, LAKE_AREA_DOW_ACRES) %>%
  mutate(DOW = as.integer(DOW))
#joins fish data with area data
mn_dat <- left_join(mn_dat, area, by = c("lake_id" = "DOW")) %>%
  #hard codes lakes that do not have area in the area file (areas taken from lake finder)
  mutate(LAKE_AREA_DOW_ACRES = as.numeric(case_when(
        lake_id == "56038800" ~ "1288",
        lake_id == "55006400" ~ "20",
        lake_id == "76014601" ~ "467",
        lake_id == "76014602" ~ "218",
        TRUE ~ as.character(LAKE_AREA_DOW_ACRES)))) %>%
  #creates binned area grouping used for minimum effort calculation
  mutate(area.group = case_when(LAKE_AREA_DOW_ACRES < 100 ~ "<100",
                                LAKE_AREA_DOW_ACRES >= 100 & LAKE_AREA_DOW_ACRES <= 300 ~ "100-300",
                                LAKE_AREA_DOW_ACRES >= 301 & LAKE_AREA_DOW_ACRES <= 600 ~ "301-600",
                                LAKE_AREA_DOW_ACRES >= 601 & LAKE_AREA_DOW_ACRES <= 1500 ~ "601-1500",
                                LAKE_AREA_DOW_ACRES >= 1501 ~ "1501+",
                                TRUE ~ "NA")) %>%
  #orders groupings so they plot well
  mutate(area.group = factor(area.group, levels = c("<100", "100-300", "301-600", "601-1500", "1501+")))


  setnames(mn_dat, c("LAKE_AREA_DOW_ACRES", "area.group"), c("lake_area_dow_acres", "area_group"))
  

  
#consolidate original filenames
  
  mn_dat[ , original_file_names := str_remove_all(paste(original_file_name_effort,original_file_name_indivfish,original_file_name, sep = ", "),
                                               ", NA"),]
  mn_dat[ , `:=` ("original_file_name_effort" = NULL ,"original_file_name_indivfish" = NULL , "original_file_name" = NULL) ,]
  
  mn_dat[ , .N ,  original_file_names]
  
  mn_dat[ , original_file_names := str_remove_all(original_file_names, "NA, ") , ]
  

#consolidate total_effort
  mn_dat[ , .N , .(is.na(total_effort), is.na(total_effort_1)) ]
  mn_dat[ is.na(total_effort) , total_effort := total_effort_1  , ]

  mn_dat[ , total_effort_1 := NULL ,]
  

#yoy as age class
  mn_dat[ , .N  ,  young_of_year]
  mn_dat[ young_of_year == "Y", age_class := "young_of_year"]
  mn_dat[ young_of_year == "N", age_class := "not_young_of_year"]
  mn_dat[ ,young_of_year := NULL]
      
  
    
# column renaming
  # clean up these names and match overall schema
#need to 1. fix current cols to match 2. add missing cols 3.drop all extras 
mn_dat <- clean_names(mn_dat) #clean up names a touch

#which date columns to keep?
dates <- mn_dat %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  mutate(date_1_effort = as.Date(date_1_effort, format = "%m/%d/%Y"),
         date_2_effort = as.Date(date_2_effort, format = "%m/%d/%Y"),
         date_1_indivfish = as.Date(date_1_indivfish, format = "%m/%d/%Y"),
         date_2_indivfish = as.Date(date_2_indivfish, format = "%m/%d/%Y")) %>% 
  select(lake_name,
         sampling_method,
    date_clean,
         date_1_effort,
         date_2_indivfish,
    date_2_effort,
         date_1_indivfish)
#dates from effort columns have the most data but still a large number of NAs
#is this to do with historical surveys? - this is looking at a gear date in a lake
mn_dat %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  group_by(survey_type) %>% 
  summarise(na_dates = sum(is.na(date_2_effort)),
            has_dates = sum(!is.na(date_2_effort)),
            survey_date_na = sum(is.na(date_clean)),
            survey_has_dates = sum(!is.na(date_clean)))
#totally!
#we can see here that every survey has a survey date but the coverage for a gearxlakexyear date is variable based on survey type
#within a total effort ident there is never more than 1 case of a date


#Denver's clean up of columns and names
mn_dat_trial <- mn_dat %>% 
  mutate(county = county_effort,
         lake_id = as.character(lake_id),
         date_survey = date_clean,
         date_total_effort_ident = as.Date(date_2_effort, format = "%m/%d/%Y"),
         date_sub_effort_ident = as.Date(NA),
         date_sample = as.Date(NA),
         year = year(date_clean),
         month = month(date_clean),
         survey_id = as.character(NA),
         survey_type_2 = as.character(NA),
         survey_type_3 = as.character(NA),
         survey_type_4 = as.character(NA),
         sampling_method_2 = sampling_method_desc,
         target_species_2 = as.character(NA),
         total_effort_1 = total_effort,
         total_effort_2 = as.numeric(NA),
         total_effort_3 = as.numeric(NA),
         total_effort_1_units = total_effort_unit,
         total_effort_2_units = as.character(NA),
         total_effort_3_units = as.character(NA),
         total_effort_nothing_caught = nothing_caught,
         water_temp_units = case_when(!is.na(water_temp) ~ "fahrenheit",
                                      TRUE ~ NA),
         water_clarity = as.numeric(NA),
         water_clarity_units = as.character(NA),
         lat_start = as.numeric(NA),
         lon_start = as.numeric(NA),
         lat_end = as.numeric(NA),
         lon_end = as.numeric(NA),
         sub_effort_ident = as.character(NA),
         sub_effort_1 = as.numeric(NA),
         sub_effort_1_units = as.character(NA),
         sub_effort_2 = as.numeric(NA),
         sub_effort_2_units = as.character(NA),
         sub_effort_nothing_caught = NA,
         species_1 = species,
         length_1 = as.numeric(length),
         length_unit_1 = length_unit, 
         length_bin = as.character(NA),
         length_bin_unit = as.character(NA),
         weight_1 = weight,
         weight_unit_1 = weight_unit,
         batch_weight = as.character(NA),
         batch_weight_unit = as.character(NA),
         flag = note_flag,
         ind_fish_ident = as.character(sample_id),
         lakesize = lake_area_dow_acres,
         lakesize_units = case_when(!is.na(lakesize) ~ "acres",
                                    TRUE ~ NA),
         area_group = as.character(area_group),
         lat_unspec = as.numeric(NA),
         lon_unspec = as.numeric(NA),
         waterbody_type = lake_type,
         location_notes_1 = location_notes,
         obs_id = as.character(row_number())
         ) %>% 
  unite("notes_1", c(garbage_bin_notes_2_indivfish,
                     reproductive_condition_notes),
                     remove = T,
                     na.rm = T) %>% 
  select(state,
         county,
         lake_name,
         lake_id,
         nhdhr_id,
         date_survey,
         date_total_effort_ident,
         date_sub_effort_ident,
         date_sample,
         year,
         month,
         survey_id,
         survey_type,
         survey_type_2,
         survey_type_3,
         survey_type_4,
         sampling_method,
         sampling_method_2,
         gear_data_notes,
         target_species,
         target_species_2,
         total_effort_ident,
         total_effort_1,
         total_effort_2,
         total_effort_3,
         total_effort_1_units,
         total_effort_2_units,
         total_effort_3_units,
         total_effort_nothing_caught,
         water_temp,
         water_temp_units,
         water_clarity,
         water_clarity_units,
         lat_start,
         lon_start,
         lat_end,
         lon_end,
         site_id,
         sub_effort_ident,
         sub_effort_1,
         sub_effort_1_units,
         sub_effort_2,
         sub_effort_2_units,
         sub_effort_nothing_caught,
         species_1,
         length_1,
         length_unit_1,
         length_bin,
         length_bin_unit,
         age,
         aging_structure_1,
         aging_structure_2,
         weight_1,
         weight_unit_1,
         batch_weight,
         batch_weight_unit,
         sex,
         age_class,
         flag,
         original_file_names,
         ind_fish_ident,
         lakesize,
         lakesize_units,
         area_group,
         lat_unspec,
         lon_unspec,
         waterbody_type,
         location_notes_1,
         notes_1,
         obs_id)
glimpse(mn_dat_trial)
  
dates <- mn_dat_trial %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  select(total_effort_ident,
         lake_name,
         sampling_method,
         date_survey,
         date_total_effort_ident)
#this shows that survey date is different than total effort ident date
#Leech is a good example of this 
#what is the survey date? it can't be the first sampling of a lake in a year... leech had ice fishing in feb but survey date shows may
#total effort ident 1 - june total effort ident date when survey data is in aug
rm(dates)

```


##############updating for the hive#####################
#this reads in directly from the hive for a quick fix
#this code needs to be used above in future iterations
```{r}
mn_data <- open_dataset(sources = file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Fish Survey Data", "Parquet files", "hive"), partitioning = c("state")) %>% 
  filter(state == "Minnesota") %>% 
  collect()

msu_xwalk <- read_csv("MGLP_FISH_LAKES_12Aug24.csv") %>% 
  filter(STATE == "MN") %>% 
  select(STATE_ID,
         LAT,
         LON) %>% 
  rename(lake_id = STATE_ID)

mn_data <- mn_data %>% 
  left_join(msu_xwalk, by = "lake_id") %>% 
  mutate(latitude_lake_centroid = case_when(is.na(lat_unspec) ~ LAT,
                                            TRUE ~ lat_unspec),
         longitude_lake_centroid = case_when(is.na(lon_unspec) ~ LON,
                                             TRUE ~ lon_unspec))


mn_data %>% 
  distinct(lake_id, .keep_all = T) %>% 
  group_by(is.na(lat_unspec), is.na(latitude_lake_centroid)) %>% 
  count()

mn_data %>% 
  distinct(nhdhr_id, .keep_all = T) %>% 
  group_by(is.na(lat_unspec), is.na(latitude_lake_centroid)) %>% 
  count()


usgs <- read_csv("lake_metadata.csv") %>% 
  filter(state == "MN") %>% 
  rename(nhdhr_id = site_id) %>% 
  select(nhdhr_id,
         centroid_lon,
         centroid_lat)


mn_data <- mn_data %>% 
  mutate(nhdhr_id = case_when(!is.na(nhdhr_id) ~ paste0("nhdhr_", nhdhr_id),
                              TRUE ~ NA)) %>% 
  left_join(usgs, by = "nhdhr_id") %>% 
  mutate(latitude_lake_centroid = case_when(is.na(latitude_lake_centroid) ~ centroid_lon,
                                            TRUE ~ latitude_lake_centroid),
         longitude_lake_centroid = case_when(is.na(longitude_lake_centroid) ~ centroid_lat,
                                             TRUE ~ longitude_lake_centroid))
mn_data %>% 
  distinct(lake_id, .keep_all = T) %>% 
  group_by(is.na(latitude_lake_centroid), is.na(centroid_lat)) %>% 
  count()

mn_data %>% 
  distinct(nhdhr_id, .keep_all = T) %>% 
  group_by(is.na(latitude_lake_centroid), is.na(centroid_lat)) %>% 
  count()


#lakes with no lat/lon
lakes_no_lat_lake_id <- mn_data %>% 
  distinct(lake_id, .keep_all = T) %>% 
  filter(is.na(latitude_lake_centroid)) 
rm(lakes_no_lat_lake_id)

lakes_no_lat_nhd <- mn_data %>% 
  distinct(nhdhr_id, .keep_all = T) %>% 
  filter(is.na(latitude_lake_centroid)) 
rm(lakes_no_lat_nhd)

#gear xwalk
gear_xwalk <- read_csv("gears_by_state.csv") %>% 
  filter(state == "Minnesota") %>% 
  rename(sampling_method_agency = gear_1,
         sampling_method_2_agency = gear_2) %>% 
  select(sampling_method_agency,
         sampling_method_2_agency,
         sampling_method_simple,
         sampling_method_1,
         sampling_method_2)

mn_data <- mn_data %>% 
  rename(sampling_method_agency = sampling_method,
         sampling_method_2_agency = sampling_method_2) %>% 
  left_join(gear_xwalk, by = c("sampling_method_agency", "sampling_method_2_agency"))

gear_check <- mn_data %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  group_by(sampling_method_agency, sampling_method_2_agency, sampling_method_simple, sampling_method_1, sampling_method_2) %>% 
  count() %>% 
  print(n = nrow(.))
rm(gear_check)


mn_data <- mn_data %>% 
  rename(sampling_method = sampling_method_1) %>% 
select(state, 
         county, 
         lake_name,
         lake_id,
         nhdhr_id,
         latitude_lake_centroid,
         longitude_lake_centroid,
         date_survey,
         date_total_effort_ident,
         date_sub_effort_ident,
         date_sample,
         year,
         month,
         survey_id,
         survey_type,
         survey_type_2,
         survey_type_3,
         survey_type_4,
         sampling_method_simple,
         sampling_method,
         sampling_method_2,
         gear_data_notes,
         target_species,
         target_species_2,
         total_effort_ident,
         total_effort_1, 
         total_effort_2,
         total_effort_3,
         total_effort_1_units,
         total_effort_2_units,
         total_effort_3_units,
         total_effort_nothing_caught,
         water_temp,
         water_temp_units,
         water_clarity,
         water_clarity_units,
         lat_start,
         lon_start,
         lat_end,
         lon_end,
         site_id,
         sub_effort_ident,
         sub_effort_1,
         sub_effort_1_units,
         sub_effort_2,
         sub_effort_2_units,
         sub_effort_nothing_caught,
         species_1,
         length_1,
         length_unit_1,
         length_bin,
         length_bin_unit,
         age,
         aging_structure_1,
         aging_structure_2,
         weight_1,
         weight_unit_1,
         batch_weight,
         batch_weight_unit,
         sex,
         age_class,
         flag,
         original_file_names,
         ind_fish_ident,
         lakesize,
         lakesize_units,
         area_group,
         lat_unspec,
         lon_unspec,
         waterbody_type,
         location_notes_1,
         notes_1,
         obs_id)
glimpse(mn_data)

write_dataset(dataset = mn_data, path = "mn_file_arrow")
```










# Save Parquet

```{r}


write_dataset(dataset = mn_dat_trial, path = "mn_file_arrow")

mn_data <- open_dataset(sources = "Data_and_Scripts/mn_file_arrow/")

glimpse(mn_data)

```


#sleuth out the MN duplicated data issues:


```{r}
#Mike code for reorganizing columns
#then open into excel an align with the schema (see these IA example files)
# fwrite(as.data.table(names(mn_dat)), file = "mn_names.csv")

# use the exported csv to align with the column names in the column schema GSheet (https://docs.google.com/spreadsheets/d/1zfevASMxRMxMYNWm3Hq1yR2Qk0zcJV_JnO0LBeODaPQ/edit#gid=0) . 
# - if you delete a column from your state's names in the sheet, the code below will drop those cols automatically from the data product.
# - put an NA in the table in each place where your data have no equivalent col and the code below will fill those with NAs in the data product
# - keep the order of the table in line with the column schema GSheet and that will automatically reorder your data to match the schema GSheet
# after aligning the names with the schema bring that back in (note that the )
mn_renamer <- fread( file = "Data_and_Scripts/Data/input/mn_renamer.csv") #read in 

#drop extras
dropcols <- names(mn_dat)[!(names(mn_dat) %in% mn_renamer[,  minnesota])]
mn_dat[ , (dropcols) := NULL , ]

#rename ia to fit the schema
mn_renamer[match(names(mn_dat),mn_renamer[,minnesota]), `fields in all parquet`]

setnames(mn_dat, 
         old = names(mn_dat),
         new = mn_renamer[match(names(mn_dat),mn_renamer[,minnesota]), `fields in all parquet`])


#missing cols
mn_renamer[,`fields in all parquet`] %in% names(mn_dat)
names(mn_dat) %in% mn_renamer[,`fields in all parquet`]

#add misssing names:
addcols <- mn_renamer[is.na(minnesota) , `fields in all parquet` ,]
mn_dat[ ,(addcols) := NA , ]

newcolorder <- mn_renamer[ ,`fields in all parquet`]


setcolorder(mn_dat, newcolorder)


#generate an obs_id

mn_dat[ , .N , obs_id ]
mn_dat[ , obs_id := .I , ]

mn_data %>% 
  group_by(lake_name, lake_id, date, sampling_method) %>% 
  collect() %>% 
  summarise(n = n_distinct(survey_type)) %>%
  filter(n>1) %>% 
  collect() %>% {. ->> dups}

mn_data %>% 
  # mutate(year = year(date)) %>%
  inner_join(dups) %>%
  group_by(lake_name, lake_id, year(date), sampling_method, survey_type) %>% 
  summarise(n_catch_all_spp = sum(!is.na(species_1))) %>% collect() %>% {. ->> dups_with_surveytype_and_catch}

dups_with_surveytype_and_catch<- setorder(as.data.table(dups_with_surveytype_and_catch, ), "lake_name", "year(date)")

#After excluding the indfish/effort mismatch
dups_with_surveytype_and_catch <- dups_with_surveytype_and_catch[!(survey_type %in% c("External Management Survey", "External Mgmt Survey"))]

```




## data checks here:
```{r}

















library(arrow)
mn_data <- open_dataset("Data_and_Scripts/Data/output/mn_file_arrow/")
glimpse(mn_data)

#add more gears from this list if desired
mn_data %>% 
  group_by(sampling_method_abbrev,sampling_method) %>% 
  count() %>% 
  compute()

mn_data %>% 
  filter(sampling_method_abbrev %in% c("GN", #gill nets common type
                                "TN" # trap nets common type
                                )) %>% 
  compute()


#mccarrons lake fish

mn_data %>% 
  filter(lake_id == 62005400) %>% 
  group_by(species.1, year(date_clean), sampling_method) %>% 
  summarize(n = n()) %>% 
  collect() %>% 
  print(n = nrow(.))

#paul F reprex


data <- data.frame(dow = c(1000100, 10000200),
                   dow_chr = c("01000100", "10000200"))

mwlaxeref::lake_id_xref %>% filter(state == "mn", local.id %in% c("01000100" , "10000200"))

local_to_nhdhr(data, from_colname = "dow", state = "mn")
local_to_nhdhr(data, from_colname = "dow_chr", state = "mn")




#daylight sampling
mn_effort_18aug2023 %>% 
  filter(sampling_method_abbrev == "EW") %>% 
  count()

mn_effort_18aug2023 %>% 
  filter(sampling_method_abbrev == "EW") %>% 
  group_by(gear_data_notes.3) %>% 
  count()

mn_effort_18aug2023 %>% 
  filter(sampling_method_abbrev == "EW") %>% 
  ggplot() +
  geom_histogram(aes(year, fill = gear_data_notes.3), alpha = .5)


mn_effort_18aug2023 %>% 
  filter(sampling_method_abbrev == "EW") %>% 
  filter(gear_data_notes.3 == "DAYLIGHT_SAMPLING:Y") %>% 
  group_by(gear_data_notes.3, garbage_bin_notes.1) %>% 
  count() %>% 
  print(n = nrow(.))

mn_effort_18aug2023 %>% 
  filter(sampling_method_abbrev == "EW") %>% 
  filter(gear_data_notes.3 != "DAYLIGHT_SAMPLING:") %>% 
  mutate(area = str_replace(garbage_bin_notes.1, "^AREA_NAME:", "")) %>% 
  group_by(gear_data_notes.3, area) %>% 
  count() %>% 
  ggplot() +
  geom_col(aes(x = area, y = n, fill = gear_data_notes.3)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


#Diversity exploration
```{r}

library(vegan)

colnames(wide_complete)
wide_complete[ , 7:112 ,]

diversity(wide_complete[ , 7:112 ,], index = "invsimpson" )


wide_complete[ , invsimpson := diversity(wide_complete[ , 7:112 ,], index = "invsimpson" ) ,]

wide_complete[ , alltime_masIS:= round(max(invsimpson),0)  ,  .(lake_id, sampling_method)]
wide_complete[ , alltime_medIS:= median(invsimpson)  ,  .(lake_id, sampling_method)]



ggplot(wide_complete[sampling_method %in% c("Standard gill nets", "Standard trap nets")] , aes(year(date_clean), invsimpson)  )+
  geom_line(aes(group = lake_id))+
  facet_grid(alltime_masIS~sampling_method)+
  geom_smooth()


ggplot(data = wide_complete[ , .(var(invsimpson) , alltime_medIS), lake_id ], aes(alltime_medIS, V1))+
  geom_point()+geom_smooth()+ ylab("variance in Diversity") + xlab("alltime median Diversity")

ggplot(data = wide_complete[ , .(var(WAE/total_effort_1.1) , alltime_medIS), lake_id ], aes(alltime_medIS, V1))+
  geom_point()+geom_smooth()+ ylab("variance in walleye cpue") + xlab("alltime median Diversity")+scale_y_log10()







```
