---
title: "d_filtered_state_combining"
author: "Denver Link"
date: "2023-10-31"
output: html_document
editor_options: 
  chunk_output_type: console
---

#library 
```{r}
library(tidyverse)
library(arrow)
library(dplyr)
library(ggplot2)
library(readr)
library(stringr)
library(maps) #to pull in the map data for geom_polygon
library(colorspace) #package with color palettes to choose from
library(viridis) #more color palettes
library(gganimate)
```


# Jan 6, 2024 - Cam issue reading in data
```{r}
mw_data <- open_dataset(sources = file.path("G:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Fish Survey Data", "Parquet files", "hive_update"), partitioning = c("state"))  %>% 
  filter(is.na(flag))
glimpse(mw_data)

mw_data %>% 
  group_by(state) %>% 
  count() %>% 
  collect()

mw_data %>% 
  select(state, lake_id, nhdhr_id, latitude_lake_centroid, longitude_lake_centroid) %>% 
  group_by(is.na(lake_id)) %>% 
  count() %>% 
  collect()

mw_data %>% 
  mutate(latitude_lake_centroid = case_when(
    is.na(latitude_lake_centroid) ~ "null",  # Replace NA with "null"
    TRUE ~ as.character(latitude_lake_centroid)  # Ensure all values are strings
  )) %>% 
  distinct(state, lake_id, lake_name, nhdhr_id, latitude_lake_centroid) %>% 
  collect() %>% 
  mutate(latitude_lake_centroid = case_when(
    latitude_lake_centroid == "null" ~ NA_real_,  # Convert "null" back to NA (as numeric)
    TRUE ~ as.numeric(latitude_lake_centroid)  # Convert back to numeric after filtering
  )) %>% 
  distinct(state, lake_id, lake_name, nhdhr_id, latitude_lake_centroid) %>% 
  group_by(state, is.na(nhdhr_id), is.na(latitude_lake_centroid)) %>% 
  count() %>% 
  collect()

mw_lake <- mw_data %>% 
  mutate(
    latitude_lake_centroid = case_when(
      is.na(latitude_lake_centroid) ~ "null",  # Replace NA with "null"
      TRUE ~ as.character(latitude_lake_centroid)  # Ensure all values are strings
    )
  ) %>% 
  distinct(state, lake_id, lake_name, nhdhr_id, latitude_lake_centroid) %>% 
  collect() %>% 
  group_by(lake_id) %>% 
  filter(!(is.na(lake_name) & n() > 1))
  

mw_lake %>% 
  group_by(lake_id, state) %>% 
  count() %>% 
  filter(n >1) %>%   
  print(n = nrow(.))
#looks like Wisconsin has 1.) for a lake_id cases where a lake exists and where it is NA and 2.) for a lake_id cases where there are slightly different names


mw_lake %>% 
  mutate(latitude_lake_centroid = case_when(latitude_lake_centroid == "null" ~ NA,
                                            TRUE ~ latitude_lake_centroid)) %>% 
  group_by(state) %>% 
  summarise(nhdhr_id_count = sum(!is.na(nhdhr_id)),
             lat = sum(!is.na(latitude_lake_centroid)),
             total_lakes = n(),
             missing_nhd = total_lakes - nhdhr_id_count,
             missing_lat = total_lakes - lat,
             coverage_nhd = nhdhr_id_count/total_lakes,
             coverage_lat = lat/total_lakes
               ) %>% 
  collect()

mw_lake %>% 
  ungroup() %>% 
  mutate(latitude_lake_centroid = case_when(latitude_lake_centroid == "null" ~ NA,
                                            TRUE ~ latitude_lake_centroid)) %>% 
  summarise(nhdhr_id_count = sum(!is.na(nhdhr_id)),
             lat = sum(!is.na(latitude_lake_centroid)),
             total_lakes = n(),
             missing_nhd = total_lakes - nhdhr_id_count,
             missing_lat = total_lakes - lat,
             coverage_nhd = nhdhr_id_count/total_lakes,
             coverage_lat = lat/total_lakes
               ) %>% 
  collect()
```


#feb 6, 2024 data to chris custer, 
```{r}
feb <- read_csv("all_state_cpue_6Feb24.csv")
indy_dates <- read_csv("indy_month_year.csv") %>% 
  mutate(total_effort_ident = as.character(total_effort_ident))
glimpse(feb)
glimpse(indy_dates)

feb %>% 
  group_by(state) %>% 
  count()

feb %>% 
  group_by(sampling_method) %>% 
  count() %>% 
  print(n = nrow(.))

feb %>% 
  group_by(species_1) %>% 
  count()

feb %>% 
  summarise(min = min(year(date), na.rm = T),
            max = max(year(date), na.rm = T))

feb %>% 
  distinct(total_effort_ident)

feb %>% 
  group_by(total_effort_ident) %>% 
  count()

lakes <- feb %>% 
  distinct(lake_name, lake_id)

feb %>% 
  summarise(n_lakes = n_distinct(lake_name, lake_id),
            n_surveys = n_distinct(total_effort_ident),
            n_years = n_distinct(year(date)))

#why is the paper saying 11,000 lakes?
feb %>% 
  summarise(n_lakes = n_distinct(lake_name, lake_id))

#leading 0s?
feb %>% 
  filter(str_detect(lake_name, "Cass")) %>% 
  distinct(lake_name, lake_id, state)
#nope

feb %>% 
  distinct(sampling_method) %>% 
  print(n = nrow(.))

feb %>% 
  distinct(total_effort_1_units)

#creating excate data that CC used 
month_year <- feb %>% 
  filter(state != "Indiana") %>% 
  mutate(month = month(date),
         year = year(date))

full <- bind_rows(indy_dates, month_year)
write_csv(full, "all_state_cpue_6Feb24.csv")

full %>% 
  group_by(is.na(date),
           is.na(year),
           is.na(month)) %>% 
  count()
glimpse(full)

full %>% 
  group_by(species_1) %>% 
  count() %>% 
  print(n = nrow(.))

full %>% 
  group_by(state) %>% 
  summarise(mean = mean(total_effort_1))
```


#8/6 cpue data aggregation with updated hive
```{r}
#reading in individual state cpe 
mn <- read_csv("filtered_cpe_files/MN_all_cpue_filtered.csv") %>% 
  mutate(lake_id = as.character(lake_id)) %>% 
  select(state, 
         lake_id,
         lake_name, 
         nhdhr_id, 
         county, 
         date_total_effort_ident, 
         month,
         year,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue,
         lat_unspec,
         lon_unspec)
mi <- read_csv("filtered_cpe_files/MI_all_cpue_filtered.csv") %>% 
  select(state, 
         lake_id,
         lake_name, 
         nhdhr_id, 
         county, 
         date_total_effort_ident, 
         month,
         year,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue,
         lat_unspec,
         lon_unspec)
il <- read_csv("filtered_cpe_files/IL_all_cpue_filtered.csv") %>% 
  mutate(lake_id = as.character(lake_id)) %>% 
  select(state, 
         lake_id,
         lake_name, 
         nhdhr_id, 
         county, 
         date_total_effort_ident, 
         month,
         year,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue,
         lat_unspec,
         lon_unspec)
sd <- read_csv("filtered_cpe_files/SD_all_cpue_filtered.csv") %>% 
  select(state, 
         lake_id,
         lake_name, 
         nhdhr_id, 
         county, 
         date_total_effort_ident, 
         month,
         year,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue,
         lat_unspec,
         lon_unspec)
ia <- read_csv("filtered_cpe_files/IA_all_cpue_filtered.csv") %>% 
  select(state, 
         lake_id,
         lake_name, 
         nhdhr_id, 
         county, 
         date_total_effort_ident, 
         month,
         year,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue,
         lat_unspec,
         lon_unspec)
indy <- read_csv("filtered_cpe_files/IN_all_cpue_filtered.csv") %>% 
  select(state, 
         lake_id,
         lake_name, 
         nhdhr_id, 
         county, 
         date_total_effort_ident, 
         month,
         year,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue,
         lat_unspec,
         lon_unspec)


cross_state <- bind_rows(mn, mi, il, sd, ia, indy)
glimpse(cross_state)

write_csv(cross_state, "all_state_cpue_13Aug24.csv")
```


#hiving
```{r}
#opening from pre-constucted file path
data <- open_dataset("Data_and_Scripts/Data/output/midwest_data", partitioning = c("state"))
glimpse(data)
#there is a "parent" folder named midwest_data
#each state gets a folder labeled state="X"
#each state parquet gets put into the respective state folder
#arrow does its magic!

#can we look at each state simultaneously? 
data %>% 
  group_by(state) %>% 
  count() %>% 
  collect()

data %>% 
  filter(species_1 == "walleye") %>% 
  group_by(state) %>% 
  count() %>% 
  collect()

data %>% 
  distinct(state, total_effort_ident) %>% 
  group_by(state) %>% 
  count() %>% 
  collect()
#this is bomb

data %>% 
  group_by(state, species_1) %>% 
  count() %>% 
  collect() %>% 
  arrange(species_1) %>% 
  print(n = nrow(.)) 

data %>% 
  group_by(state) %>% 
  summarise(min.year = min(year, na.rm = T),
            max.year = max(year, na.rm = T)) %>% 
  collect()

data %>% 
  group_by(state) %>% 
  summarise(min.month = min(month, na.rm = T),
            max.month = max(month, na.rm = T)) %>% 
  collect()

#trying from drive
data.2 <- open_dataset(sources = file.path("D:", "Shared drives", "Hansen Lab", "RESEARCH PROJECTS", "Fish Survey Data", "Parquet files", "hive"), partitioning = c("state"))

glimpse(data.2)

data.2 %>% 
  group_by(state) %>% 
  count() %>% 
  collect()

data.2 %>% 
  filter(species_1 == "walleye") %>% 
  group_by(state) %>% 
  count() %>% 
  collect()
#it works like a charm

#getting some basic statistics
data.2 %>% 
  filter(!is.na(age)) %>% 
  summarise(min.year = min(year, na.rm = T),
            max.year = max(year, na.rm = T)) %>% 
  collect()

data.2 %>% 
  filter((sub_effort_nothing_caught == "FALSE" | is.na(sub_effort_nothing_caught))) %>%
  filter((total_effort_nothing_caught == "FALSE" | is.na(total_effort_nothing_caught))) %>% 
  filter(!is.na(age)) %>% 
  glimpse()


data.2 %>% 
  filter(!is.na(age)) %>%
  summarise(n_distinct(lake_id)) %>% 
  collect()

data.2 %>% 
  filter(!is.na(age)) %>%
  summarise(n_distinct(state)) %>% 
  collect()

#difference in MN between agency
##no leading zero on lake ids in Minnesota 
data.2 %>% 
  filter(state == "Minnesota") %>% 
  filter(lake_id == "4003000") %>% 
  filter(sampling_method == "Standard gill net sets") %>% 
  filter(year == 1991) %>%
  group_by(species_1) %>% 
  count() %>% 
  collect()

data.2 %>% 
  filter(state == "Minnesota") %>% 
  filter(lake_id == "4003000") %>% 
  filter(sampling_method == "Standard gill net sets") %>% 
  filter(year == 1991) %>% 
  glimpse()

data.2 %>% 
  filter(state == "Minnesota") %>% 
  filter(year < 2002) %>% 
  filter(sampling_method == "Standard gill net sets") %>% 
  group_by(is.na(length_1), survey_type) %>% 
  count() %>% 
  collect()

data.2 %>% 
  filter(state == "Minnesota") %>% 
  filter(year < 2002) %>% 
  filter(sampling_method == "Standard gill net sets") %>% 
  filter(lake_id == "4003000") %>%
  group_by(year, survey_type) %>% 
  count() %>% 
  collect() %>% 
  print(n = nrow(.))

data.2 %>% 
  filter(state == "Minnesota") %>% 
  filter(year >= 2002) %>% 
  filter(sampling_method == "Standard gill net sets") %>% 
  filter(lake_id == "4003000") %>%
  group_by(year, survey_type) %>% 
  count() %>% 
  collect() %>% 
  print(n = nrow(.))
  



glimpse(wi_data)
wi_data %>% 
  filter(!is.na(age)) %>%
  filter(year(date) >1800 & year(date) < 2025) %>% 
  summarise(min.year = min(year(date), na.rm = T),
            max.year = max(year(date), na.rm = T)) %>% 
  collect()

wi_data %>% 
  filter(!is.na(age)) %>%
  filter(total_effort_nothing_caught == "FALSE" | is.na(total_effort_nothing_caught)) %>% 
  filter(sub_nothing_caught == "FALSE" | is.na(sub_nothing_caught)) %>% 
  glimpse()

wi_data %>% 
  distinct(lake_id) %>% 
  count() %>% 
  collect()

wi_data %>% 
  summarise(n_distinct(lake_id)) %>% 
  collect()
```


#2/5 cpe data dump
```{r}
#reading in individual state cpe 
wi <- read_csv("filtered_cpe_files/WI_all_cpue_filtered.csv") %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
         date,
         sampling_method,
        total_effort_ident,
         total_effort_1,
         total_effort_1_unit,
         species_1,
         count,
         cpue) %>% 
  rename(total_effort_1_units = total_effort_1_unit) %>% 
  mutate(lake_id = as.character(lake_id),
         total_effort_ident = as.character(total_effort_ident))
mn <- read_csv("filtered_cpe_files/MN_all_cpue_filtered.csv") %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
    lat_unspec,
    lon_unspec,
         date,
         sampling_method,
    total_effort_ident,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue) %>% 
  mutate(lake_id = as.character(lake_id),
         total_effort_ident = as.character(total_effort_ident))
mi <- read_csv("filtered_cpe_files/MI_all_cpue_filtered.csv") %>% 
  rename(lake_name = lake_name.1,
         date = date.1,
         nhdhr_id = nhdhr.id,
         total_effort_1 = total_effort_1.1_effort,
         total_effort_1_units = effort_units.1) %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
         date,
    lat_unspec_effort,
    lon_unspec_effort,
    effort_ident,
         sampling_method,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue) %>% 
  mutate(lake_id = as.character(lake_id),
         lat_unspec = lat_unspec_effort,
         lon_unspec = lon_unspec_effort,
         total_effort_ident = as.character(effort_ident)) %>% 
  select(-effort_ident,
         -lat_unspec_effort,
         -lon_unspec_effort)
il <- read_csv("filtered_cpe_files/IL_all_cpue_filtered.csv") %>% 
  rename(nhdhr_id = nhdr_id) %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
    lat_unspec,
    lon_unspec,
         date,
         sampling_method,
    total_effort_ident,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue) %>% 
  mutate(lake_id = as.character(lake_id),
         total_effort_ident = as.character(total_effort_ident))
sd <- read_csv("filtered_cpe_files/SD_all_cpue_filtered.csv") %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
    lat_unspec,
    lon_unspec,
         date,
         sampling_method,
    total_effort_ident,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue) %>% 
  mutate(lake_id = as.character(lake_id),
         total_effort_ident = as.character(total_effort_ident))
ia <- read_csv("filtered_cpe_files/IA_all_cpue_filtered.csv") %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
    lat_unspec,
    lon_unspec,
         date,
         sampling_method,
    total_effort_ident,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue) %>% 
  mutate(lake_id = as.character(lake_id),
         total_effort_ident = as.character(total_effort_ident))
indy <- read_csv("filtered_cpe_files/IN_all_cpue_filtered.csv") %>% 
  select(state,
    lake_id,
         lake_name,
         nhdhr_id,
         county,
         date,
    month,
    year,
         sampling_method,
    total_effort_ident,
         total_effort_1,
         total_effort_1_units,
         species_1,
         count,
         cpue) %>% 
  mutate(lake_id = as.character(lake_id),
         total_effort_ident = as.character(total_effort_ident))

#make sure i get ride of columns that are not survey level or helpful to Chris
cross_state <- bind_rows(wi, mn, mi, il, sd, ia, indy)
glimpse(cross_state)
```

#comparison of data
```{r}
#old 
old <- read_csv("all_state_cpue_8Dec23.csv") %>% 
  rename(date = date_1,
         lake_name = lake_name_1) %>% 
  mutate(filtering = "old")

#new
new <- read_csv("all_state_cpue_6Feb24.csv") %>% 
  mutate(filtering = "new")

#combined
compare <- bind_rows(old, new)

compare %>% 
  group_by(filtering, state) %>% 
  count() %>% 
  pivot_wider(id_cols = state,
              names_from = filtering,
              values_from = n)
#surveys by state

table.gears <- compare %>% 
  distinct(state, sampling_method, filtering) %>% 
  pivot_wider(id_cols = state,
              names_from = filtering,
              values_from = sampling_method)
table.gears
  
#gear types by state
compare %>% 
  filter(state == "Illinois") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

compare %>% 
  filter(state == "Indiana") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

compare %>% 
  filter(state == "Iowa") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

compare %>% 
  filter(state == "Michigan") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

compare %>% 
  filter(state == "Minnesota") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

compare %>% 
  filter(state == "South Dakota") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

compare %>% 
  filter(state == "Wisconsin") %>% 
  ggplot() +
  geom_bar(aes(x = sampling_method, fill = filtering), position = "dodge") +
  facet_wrap(~state, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#units 
compare %>% 
  distinct(state, sampling_method, total_effort_1_units) %>% 
  print(n = nrow(.))

#wisconsin
compare %>% 
  filter(state == "Wisconsin" & filtering == "new") %>% 
  ggplot() +
  geom_histogram(aes(total_effort_1)) +
  facet_wrap(~sampling_method, scales = "free")

check <- compare %>% 
  filter(nhdhr_id == "nhdhr_77358700" & year(date) == 2000) 

#old vs new gears
compare %>% 
  filter(state == "Iowa") %>% 
  ggplot() +
  geom_histogram(aes(total))

#check coords
new %>%
  distinct(lake_id, .keep_all = T) %>%
  group_by(state) %>%
  summarise(no.lats = sum(is.na(lat_unspec)),
            has.lats = sum(!is.na(lat_unspec)))

new %>% 
  filter(state == "Illinois") %>% 
  filter(is.na(lat_unspec)) %>% 
  count()

new %>% 
  filter(state == "Indiana") %>% 
  distinct(lake_id) %>% 
  count()

#making na indy dates work for Chris
check <- indy %>% 
  distinct(total_effort_ident, date, month, year) 

write_csv(indy, "indy_month_year.csv")

#only 10 Wisconsin cert gill nets
library(mwlaxeref)

new %>% 
  filter(state == "Wisconsin" & sampling_method == "vertical_gill_net") %>% 
  group_by(sampling_method, nhdhr_id, lat_unspec) %>% 
  count()

wis_vert <- new %>% 
  filter(state == "Wisconsin" & sampling_method == "vertical_gill_net")

wis_vert <- new %>% 
  filter(state == "Wisconsin" & sampling_method == "vertical_gill_net") %>% 
  local_to_nhdhr(from_colname = "lake_id", states = "wi") %>% 
  select(-nhdhr_id,
         -filtering) %>% 
  rename(nhdhr_id = nhdhr.id)



write_csv(wis_vert, "vert_gill_wi_nhdids.csv")

#Minnesota vert gill nets
new %>% 
  filter(state == "Minnesota") %>% 
  group_by(sampling_method) %>% 
  count()

mn_data %>% 
  group_by(total_effort_ident) %>% 
  filter(sampling_method == "Standard Vertical Gillnet") %>% 
  count() %>% 
  collect()

mn_vert <- mn_data %>% 
  group_by(total_effort_ident) %>% 
  filter(sampling_method == "Standard Vertical Gillnet") %>% 
  collect() %>% 
  distinct(total_effort_ident, .keep_all = T)

mn_data %>% 
  group_by(total_effort_ident) %>% 
  filter(sampling_method == "Standard Vertical Gillnet") %>% 
  collect() %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  group_by(month(date),
           survey_type, 
           total_effort_1,
           area_group) %>% 
  count() %>% 
  print(n = nrow(.))

adult_cisco_cpue %>% 
  filter(sampling_method == "Standard Vertical Gillnet") %>%
  group_by(month(date),
           survey_type, 
           total_effort_1) %>% 
  count()

mn_data %>% 
  filter(sampling_method == "Standard Vertical Gillnet") %>%
  distinct(total_effort_ident, flag) %>% 
  group_by(total_effort_ident, flag) %>% 
  count() %>% 
  collect() %>% 
  print(n = nrow(.))

new %>% 
  filter(state == "Minnesota") %>% 
  group_by(sampling_method) %>% 
  count()

#how many surveys with paired gears are there in Minnesota?
new %>% 
  filter(state == "Minnesota") %>% 
  filter(sampling_method != "Standard Vertical Gillnet") %>% 
  distinct(total_effort_ident, .keep_all = T) %>% 
  group_by(lake_id, year(date)) %>% 
  count() %>% 
  filter(n > 1)

new %>% 
  summarise(min(year(date), na.rm = T),
            max(year(date), na.rm = T))

new %>% 
  summarise(sum(count)) %>% 
  collect()

new %>% 
  summarise(n_distinct(lake_id))

new %>% 
  summarise(n_distinct(state))
``` 

#cool new figures with the new filtered data
```{r}
#read in cpe data
cpe <- read_csv("all_state_cpue_6Feb24.csv")

#just a quick glimpse of what we are deal with 
cpe %>% 
  filter(species_1 == "largemouth_bass") %>% 
  filter(!(state == "Minnesota" & cpue > 400)) %>% 
  ggplot() +
  geom_histogram(aes(cpue)) +
  facet_wrap(~state, scales = "free")
ggsave("lmb_cpue_histo.png", dpi = 600, width = 11, height = 7)

#connect that nhdid to a lat/lon
glm_metadat <- read_csv("D:/Shared drives/Hansen Lab/RESEARCH PROJECTS/Fish Survey Data/Temp_projections_Summaries/glm_lake_metadata.csv") %>% 
  filter(state %in% c("IA", "IL", "MN", "WI", "MI", "IN", "SD")) %>% 
  select(site_id, centroid_lon, centroid_lat) %>% 
  mutate(nhdhr_id = str_replace(site_id, "nhdhr_", "")) %>% 
  select(-site_id)

cpe.spatial <- cpe %>% 
  left_join(glm_metadat) %>% 
  mutate(centroid_lon = case_when(is.na(centroid_lon) ~ lon_unspec,
                                  TRUE ~ centroid_lon),
         centroid_lat = case_when(is.na(centroid_lat) ~ lat_unspec,
                                  TRUE ~ centroid_lat))

cpe.spatial %>% 
  group_by(is.na(nhdhr_id)) %>% 
  count(is.na(centroid_lon))
#most cpe records that are not na found a lat/lon pair

cpe.spatial %>% 
  group_by(state) %>% 
  count(is.na(centroid_lon))
#everything looks pretty good besides IN

#map
#basic map for reference code
Midwest <- map_data("state", region = c("minnesota", "wisconsin", "south dakota", "iowa", "illinois", "indiana", "michigan"))
lll_lakes_map <- ggplot()+
  geom_polygon(data = Midwest, aes(x = long, y = lat, group = group,), color = "black", fill = "azure1")+
  coord_fixed(1.3)+
  guides(fill = FALSE)
lll_lakes_map

#cpe scaled within state
lmb_cpe <- cpe.spatial %>%
  filter(species_1 == "largemouth_bass") %>%
  group_by(lake_id) %>% 
  mutate(avg_cpe = median(cpue)) %>% 
  distinct(lake_id, avg_cpe, .keep_all = T) %>% 
  group_by(state)%>%
  mutate(percentile = percent_rank(avg_cpe))%>%
  ungroup(state)%>%
  mutate(zero_flag = if_else(avg_cpe == 0, T, F))%>%
  mutate(cpue_no_0 = na_if(avg_cpe, 0))

lmb_cpe_map <- ggplot()+
  geom_polygon(data = Midwest, aes(x = long, y = lat, group = group,), color = "black", fill = "white")+
  coord_fixed(1.3)+
  guides(fill = FALSE)+
  geom_point(data = lmb_cpe, aes(x = centroid_lon, y = centroid_lat, color = percentile, shape = zero_flag, alpha = zero_flag))+
  theme_bw()+
  labs(color = "Within State CPUE Percentile", alpha = "Within State CPUE Percentile", shape = NA)+
  scale_color_viridis(begin = 0, end = .95, direction = -1, option = "C")+
  scale_shape_manual(values = c(19,4), guide = "none")+
  scale_alpha_manual(values = c(.5, .25), guide = "none")
lmb_cpe_map
ggsave("lmb_cpe_map.png", dpi = 600, height = 7, width = 11)
```


#mergeing cross-state to covariates
-data taken from temp projections summaries
 -clarity form the metadata
 -temp data from the temp metrics feather file
```{r}
#cross state cpue data
cross_state <- read_csv("all_state_cpue_8Dec23.csv") %>% 
  mutate(year = year(date_1))

#covariate data
temp <- read_feather("lake_temperature_metrics_GLM_NLDAS.feather", col_select = NULL, as_data_frame = TRUE, mmap = TRUE) %>% 
  select(site_id, year, stratification_onset_yday, stratification_duration, mean_surf_JulAugSep, ice_on_date, ice_off_date) %>% 
  rename(nhdhr_id = site_id)

clarity <- read_csv("glm_lake_metadata.csv") %>% 
  select(site_id, max_depth, area, clarity, elevation) %>% 
  rename(nhdhr_id = site_id)

cross_state_covary <- cross_state %>% 
  left_join(clarity) %>% 
  left_join(temp, by = c("nhdhr_id",
                         "year"))

cross_state_covary %>% 
  filter(is.na(nhdhr_id)) %>% 
  glimpse()

write_csv(cross_state_covary, "all_state_cpue_covariates.csv")
```



#map of cpue by state
```{r}

# lake info from LAGOS, https://portal.edirepository.org/nis/mapbrowse?packageid=edi.854.1 (want 'lake_information' file)
lagos_lake_info <- read_csv("LAGOS_lake_information_20Oct2023.csv")
nhd_lat_longs <- lagos_lake_info %>%
  select(lake_nhdid, lake_lat_decdeg, lake_lon_decdeg) #removes unnecessary columns

wi_cpue_lat_long <- wi %>%
  mutate(lake_nhdid = str_replace(nhdhr_id, "nhdhr_", "")) %>%  #remove nhdhr_ prefix from id
  left_join(nhd_lat_longs, by = "lake_nhdid")
mn_cpue_lat_long <- mn %>% 
  mutate(lake_nhdid = str_replace(nhdhr.id, "nhdhr_", "")) %>%    #remove nhdhr_ prefix from id
  left_join(nhd_lat_longs, by = "lake_nhdid")
mi_cpue_lat_long <- mi %>% 
  mutate(lake_nhdid = str_replace(nhdhr.id, "nhdhr_", "")) %>%    #remove nhdhr_ prefix from id
  left_join(nhd_lat_longs, by = "lake_nhdid")
  
#checked for lakes that didn't get lat longs with following code placed after the left join above 
  # %>% filter(is.na(lake_lat_decdeg))%>%group_by(lake_id)%>%summarise(total = n())
#  84600, 2621900, 2674100, 2691500 check out these nhd ids later

#basic map for reference code
Midwest <- map_data("state", region = c("minnesota", "wisconsin", "north dakota", "south dakota", "iowa", "illinois", "indiana", "michigan"))
midwest_map <- ggplot(data = Midwest)+
  geom_polygon(aes(x = long, y = lat, group = group, fill = region), color = "white")+
  coord_fixed(1.3)+
  guides(fill = FALSE)
midwest_map

#wisconsin map
WI <- map_data("state", region = "wisconsin") #get basic WI map
wi_map <- ggplot(data = WI)+
  geom_polygon(aes(x = long, y = lat, group = group), fill = "white", color = "black")+
  coord_fixed(1.3)+
  geom_point(data = wi_cpue_lat_long, aes(x = lake_lon_decdeg, y = lake_lat_decdeg, color = cpue ), alpha = .25)+
  facet_wrap(species_1~sampling_method)+
  scale_color_viridis(option = "H")
wi_map

#Minnesota map
MN <- map_data("state", region = "minnesota") #get basic WI map
mn_map <- ggplot(data = MN)+
  geom_polygon(aes(x = long, y = lat, group = group), fill = "white", color = "black")+
  coord_fixed(1.3)+
  geom_point(data = mn_cpue_lat_long, aes(x = lake_lon_decdeg, y = lake_lat_decdeg, color = cpue), alpha = .25)+
  facet_wrap(species_1~sampling_method)+
  scale_color_viridis(option = "H")
mn_map

#Michigan map
MI <- map_data("state", region = "michigan") #get basic WI map
mi_map <- ggplot(data = MI)+
  geom_polygon(aes(x = long, y = lat, group = group), fill = "white", color = "black")+
  coord_fixed(1.3)+
  geom_point(data = mi_cpue_lat_long, aes(x = lake_lon_decdeg, y = lake_lat_decdeg, color = cpue), alpha = .25)+
  facet_wrap(species_1~sampling_method)+
  scale_color_viridis(option = "H")
mi_map

#all states together - still needs work
MN_MI_WI <- map_data("state", region = c("minnesota", "wisconsin", "michigan"))
MN_MI_WI_map <- ggplot(data = MN_MI_WI)+
  geom_polygon(aes(x = long, y = lat, group = group), fill = "white", color = "black")+
  coord_fixed(1.3)+
  geom_point(data = cross_state_wae, aes(x = lake_lon_decdeg, y = lake_lat_decdeg, color = log(cpue)), alpha = .5)+ #can repeat this line for each state if needed
  facet_wrap(.~sampling_method)+
  scale_color_viridis(option = "H")+
  labs(title = "Filtered Walleye CPUE data by gear", x = "longitude", y = "latitude")
MN_MI_WI_map

#time with walleye?
ggplot(data = MN)+
  geom_polygon(aes(x = long, y = lat, group = group), fill = "white", color = "black")+
  coord_fixed(1.3)+
  geom_point(data = mn_cpue_lat_long %>% 
               filter(species_1 == "walleye" & sampling_method == "Standard gill net sets"), aes(x = lake_lon_decdeg, y = lake_lat_decdeg, color = cpue), alpha = .25)+
  facet_wrap(~year(date_1))+
  scale_color_viridis(option = "H")

###########cpe through time###################
cpe %>% 
  filter(species_1 == "walleye") %>% 
  group_by(sampling_method) %>% 
  count() %>% 
  print(n= nrow(.))

walleye_gillnet <- cpe %>% 
  filter(species_1 == "walleye") %>% 
  filter(str_detect(sampling_method, "gill net") | str_detect(sampling_method, "gill_net")) %>% 
  group_by(lake_id) %>% 
  filter(n() > 2)

#only ten largest lakes in MN
walleye_gillnet %>% 
  filter(lake_id %in% c("4003501",
                        "48000200",
                        "11020300",
                        "11014700",
                        "69037800",
                        "69084500",
                        "4003000",
                        "27013300",
                        "56024200")) %>%
  filter(year(date) > 1979) %>% 
  ggplot() +
  theme_bw() +
  geom_jitter(aes(year(date), cpue, color = lake_name), alpha = 0.5) +
  geom_line(aes(year(date), cpue, color = lake_name), stat = "smooth", se = FALSE, alpha = 0.6) +
  geom_smooth(aes(year(date), cpue))  # Adjust alpha here

#all gill netted walleye
walleye_gillnet %>% 
  filter(cpue < 50) %>% 
  ggplot() +
  geom_jitter(aes(year(date), cpue, color = lake_id)) +
  geom_line(aes(year(date), cpue, color = lake_id), stat = "smooth", se = FALSE, alpha = .3, method = lm) +
  geom_smooth(aes(year(date), cpue)) +
  theme_bw() +
  theme(legend.position = "none") 
#use filtering for walleye in other states but count specific fish of interest for further plotting
```


#comparing acorss states
```{r}
#tallies of surveys
cross_state %>% 
  filter(state == "Minnesota") %>% 
  mutate(sampling_method = case_when(str_detect(sampling_method, "Standard gill") ~ "gill net",
                                     TRUE ~ "trap net")) %>% 
  ggplot() +
  geom_bar(aes(sampling_method)) +
  facet_wrap(~species_1) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

cross_state %>% 
  filter(state == "Wisconsin") %>% 
  ggplot() +
  geom_bar(aes(sampling_method)) +
  facet_wrap(~species_1) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

cross_state %>% 
  filter(state == "Michigan") %>% 
  ggplot() +
  geom_bar(aes(sampling_method)) +
  facet_wrap(~species_1) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  


#histogram of cpues
cross_state %>% 
  filter(cpue < 100) %>% 
  ggplot() +
  geom_histogram(aes(cpue), alpha = .6) +
  facet_grid(species_1~state, scales = "free")

cross_state %>% 
  filter(state == "Minnesota") %>% 
  ggplot()+
  geom_histogram(aes(cpue), alpha = .6) +
  facet_grid(~species_1, scales = "free")

cross_state %>% 
  filter(state == "Wisconsin") %>% 
  ggplot()+
  geom_histogram(aes(cpue), alpha = .6) +
  facet_grid(~species_1, scales = "free")

cross_state %>% 
  filter(state == "Michigan") %>% 
  ggplot()+
  geom_histogram(aes(cpue), alpha = .6) +
  facet_grid(~species_1, scales = "free")

#histogram of timing

#not sure why this plot is showing up funky? - Michigan?
cross_state %>% 
  mutate(julian_day = yday(date_1)) %>% 
  ggplot() +
  geom_histogram(aes(julian_day, fill = state), alpha = .4, binwidth = 5) +
  facet_wrap(~state, scales = "free")

cross_state %>% 
  mutate(julian_day = yday(date_1)) %>% 
  ggplot() +
  geom_density(aes(julian_day, fill = state), alpha = .4)

cross_state %>% 
  mutate(julian_day = yday(date_1)) %>% 
  ggplot() +
  geom_histogram(aes(julian_day, fill = state), binwidth = 5) +
  facet_wrap(~state)
```

#gears across states?
```{r}
cross_state <- read_csv("mn_wi_mi_filtered_cpue_11NOV23.csv")

cross_state %>% 
  group_by(species_1, state, sampling_method) %>% 
  count() %>% 
  print(n = nrow(.))
```

#plot for presentation
```{r}
plot <- mn_data %>% 
  filter(sampling_method_abbrev == "GN") %>% 
  filter(species.1 %in% c("walleye", "northern_pike", "largemouth_bass", "black_crappie")) %>% 
  collect() %>% 
  group_by(effort_ident, species.1) %>% 
  summarise(lake_id = unique(lake_id), sampling_method = unique(sampling_method), area_group = unique(area_group), date.1 = unique(date_clean), effort = unique(total_effort_1.1), n = n()) %>% 
  mutate(cpue = n/effort)

plot %>% 
  ungroup() %>% 
  filter(effort <= 20) %>% 
ggplot() +
  geom_smooth(aes(x = effort, y = cpue, color = area_group)) +
  facet_wrap(~ species.1, scales = "free")

plot %>% 
  ungroup() %>% 
  filter(effort <= 20) %>% 
ggplot() +
  geom_smooth(aes(x = effort, y = cpue)) +
  facet_wrap(~ species.1, scales = "free")
```


#notes for workshop- wisconsin
```{r}
#reading in data 
wi_inland_cpue <- read_csv("Data_and_Scripts/wi_data/wi_inland_cpue_19Mar2021.csv")
glimpse(wi_inland_cpue)

wi_inland_effort <- read_csv("Data_and_Scripts/wi_data/wi_inland_effort_19Mar2021.csv")
glimpse(wi_inland_effort)
inland_effort_keep <- wi_inland_effort %>% 
  group_by(gear,
         distance.shocked,
         weather.description,
         adverse.condition,
         volts,
         amps,
         pulse.rate.percent,
         duty.cycle,
         current.type,
         number.of.dippers,
         dipnet.bar.mesh.size,
         type.of.pass,
         deployment.depth,
         water.clarity,
         water.clarity.feet.amt,
         probe.no,
         probe.no.amt,
         run.type,
         average.droppers.per.probe) %>% 
  summarise(records = n()) 
write_csv(inland_effort_keep, "wi_effort_file_notes.csv")

wi_inland_fishobservations <- read_csv("Data_and_Scripts/wi_data/wi_inland_fishobservations_19Mar2021-001.csv")
glimpse(wi_inland_fishobservations) 
fishobs_notes <- wi_inland_fishobservations %>% 
  group_by(visit.type,
         net.number,
         mark.given,
         mark.found,
         second.mark.found,
         tag.number.given,
         second.tag.number.given,
         tag.number.found,
         second.tag.number.found,
         primary.survey.purpose,
         secondary.survey.purpose) %>% 
  summarise(n = n())
write_csv(fishobs_notes, "wi_fish_obs_notes.csv")

wi_inland_lenage <- read_csv("Data_and_Scripts/wi_data/wi_inland_lenage_19Mar2021.csv")
glimpse(wi_inland_lenage)

wi_win_cpe <- read_csv("Data_and_Scripts/wi_data/wi_winnebago_cpue_23Apr2021.csv")
glimpse(wi_win_cpe)

wi_win_fish <- read_csv("Data_and_Scripts/wi_data/wi_winnebago_fishobservations_23April2021.csv")
glimpse(wi_win_fish)

wi_cisco <- read_csv("Data_and_Scripts/wi_data/wi_cisco.csv")
glimpse(wi_cisco)
wi_cisco_notes <- wi_cisco %>% 
  group_by(Maxdpth,
         Mndepth,
         Stratind,
         Shore,
         Alk,
         Conduct,
         TSI,
         Cisco,
         C_Lst_yr,
         C_Source,
         VGN_Date,
         VGN_NN,
         VGN_Cisco,
         VGN_CiscoNN,
         VGN_CiscoRA,
         Overall_CiscoNN,
         Overall_CiscoRA,
         Overall_SmeltNN,
         Overall_LWhiteNN,
         TDO3,
         TDO3_Date,
         Slimysc,
         Othr_cld,
         Comments) %>% 
  summarize(n = n())
```

#cisco - wisco and michginan
```{r}
#wisconsin
wi_data <- open_dataset("Data_and_Scripts/wi_file_arrow")

wi_data %>% 
  distinct(lake_id, date_1, sampling_method) %>% 
  group_by(sampling_method) %>% 
  summarise(n = n()) %>% 
  collect() %>% 
  print(n = nrow(.))

wi_data %>% 
  filter(sampling_method == "vertical_gill_net") %>% 
  distinct(lake_id, date_1) %>% 
  collect() %>% 
  group_by(month(date_1)) %>% 
  count()

wi_data %>% 
  group_by(species_1) %>% 
  count() %>% 
  collect() %>% 
  print(n = nrow(.))

cisco_surveys <- wi_data %>% 
  filter(sampling_method == "vertical_gill_net") %>% 
  distinct(lake_name_1, lake_id, date_1) %>% 
  collect()

#Michigan 
mi_data <- open_dataset("Data_and_Scripts/mi_file_arrow")

mi_data %>% 
  distinct(lake_id, date.1, sampling_method) %>% 
  group_by(sampling_method) %>% 
  count() %>% 
  collect()

mi_data %>% 
  filter(species.1 == "cisco") %>%
  distinct(lake_id, date.1, sampling_method) %>% 
  group_by(sampling_method) %>% 
  count() %>% 
  collect()
#cisco are only being caught in 

#minnesota
mn_data <- open_dataset("Data_and_Scripts/mn_file_arrow")

mn_data %>% 
  group_by(species.1) %>% 
  count() %>% 
  collect() %>% 
  arrange(species.1) %>% 
  print(n = nrow(.))

mn_data %>% 
  filter(species.1 == "cisco") %>%
  distinct(lake_id, date_clean, sampling_method) %>% 
  group_by(sampling_method) %>% 
  count() %>% 
  collect() %>% 
  print(n = nrow(.))
```

